{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G6uf2OSqESJz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Lambda, Activation, Embedding, Input, Dense, Reshape, Flatten, Dropout, Multiply, Concatenate, Dot\n",
    "\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGiZAec22gef"
   },
   "source": [
    "# Test model on Steam Video Games [dataset](https://www.kaggle.com/tamber/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meUMpBfj2mop"
   },
   "source": [
    "## Data loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "x2ctpQwbNMqx",
    "outputId": "d7dba65d-d24d-4005-c60e-c05336e820fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>game</th>\n",
       "      <th>hours</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5250</td>\n",
       "      <td>Alien Swarm</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5250</td>\n",
       "      <td>Cities Skylines</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5250</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5250</td>\n",
       "      <td>Counter-Strike Source</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5250</td>\n",
       "      <td>Day of Defeat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128799</th>\n",
       "      <td>309626088</td>\n",
       "      <td>Age of Empires II HD Edition</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128800</th>\n",
       "      <td>309812026</td>\n",
       "      <td>Counter-Strike Nexon Zombies</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128801</th>\n",
       "      <td>309812026</td>\n",
       "      <td>Robocraft</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128802</th>\n",
       "      <td>309824202</td>\n",
       "      <td>Dota 2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128803</th>\n",
       "      <td>309903146</td>\n",
       "      <td>Dota 2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128804 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id                          game  hours  view\n",
       "0            5250                   Alien Swarm    5.9     1\n",
       "1            5250               Cities Skylines  145.0     1\n",
       "2            5250                Counter-Strike    1.0     1\n",
       "3            5250         Counter-Strike Source    1.0     1\n",
       "4            5250                 Day of Defeat    1.0     1\n",
       "...           ...                           ...    ...   ...\n",
       "128799  309626088  Age of Empires II HD Edition    7.7     1\n",
       "128800  309812026  Counter-Strike Nexon Zombies    1.0     1\n",
       "128801  309812026                     Robocraft    1.0     1\n",
       "128802  309824202                        Dota 2    1.7     1\n",
       "128803  309903146                        Dota 2    1.2     1\n",
       "\n",
       "[128804 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_ratings = pd.read_csv('steam-200k.csv', index_col=None, header=None)\n",
    "steam_ratings.columns=['user_id', 'game', 'action', 'hours', 'none']\n",
    "steam_ratings = steam_ratings.drop('none', axis=1)\n",
    "\n",
    "# Group interations by user_id and game\n",
    "steam_ratings = steam_ratings.groupby(['user_id', 'game'])\\\n",
    "                                      .sum()['hours'].reset_index()\n",
    "\n",
    "steam_ratings['view'] = 1 \n",
    "steam_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G977zrXJ2plk"
   },
   "source": [
    "Remove users that had less than 5 interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "WoN49-qnQYrD",
    "outputId": "5cea0540-1b2b-4126-ab11-4437453111a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>game</th>\n",
       "      <th>hours</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5250</td>\n",
       "      <td>Alien Swarm</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5250</td>\n",
       "      <td>Cities Skylines</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5250</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5250</td>\n",
       "      <td>Counter-Strike Source</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5250</td>\n",
       "      <td>Day of Defeat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115134</th>\n",
       "      <td>309404240</td>\n",
       "      <td>AdVenture Capitalist</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115135</th>\n",
       "      <td>309404240</td>\n",
       "      <td>Mitos.is The Game</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115136</th>\n",
       "      <td>309404240</td>\n",
       "      <td>Team Fortress 2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115137</th>\n",
       "      <td>309404240</td>\n",
       "      <td>Transformice</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115138</th>\n",
       "      <td>309404240</td>\n",
       "      <td>Unturned</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115139 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id                   game  hours  view\n",
       "0            5250            Alien Swarm    5.9     1\n",
       "1            5250        Cities Skylines  145.0     1\n",
       "2            5250         Counter-Strike    1.0     1\n",
       "3            5250  Counter-Strike Source    1.0     1\n",
       "4            5250          Day of Defeat    1.0     1\n",
       "...           ...                    ...    ...   ...\n",
       "115134  309404240   AdVenture Capitalist    1.7     1\n",
       "115135  309404240      Mitos.is The Game    3.2     1\n",
       "115136  309404240        Team Fortress 2    3.2     1\n",
       "115137  309404240           Transformice    1.3     1\n",
       "115138  309404240               Unturned   14.0     1\n",
       "\n",
       "[115139 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_interactions = 5\n",
    "users_interactions_count_df = steam_ratings.groupby('user_id').size()\n",
    "valid_user_ids = users_interactions_count_df[users_interactions_count_df >= min_interactions].reset_index()[['user_id']]\n",
    "filtered_ratings = steam_ratings.merge(valid_user_ids, how = 'right', left_on = 'user_id', right_on = 'user_id')\n",
    "filtered_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "B8jPvjr9X8XH",
    "outputId": "bf761416-b298-4d71-d955-a3df33bd0c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users: 3757\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>game</th>\n",
       "      <th>hours</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>Alien Swarm</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>846</td>\n",
       "      <td>Cities Skylines</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>972</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>978</td>\n",
       "      <td>Counter-Strike Source</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1125</td>\n",
       "      <td>Day of Defeat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id                   game  hours  view\n",
       "0        0      226            Alien Swarm    5.9     1\n",
       "1        0      846        Cities Skylines  145.0     1\n",
       "2        0      972         Counter-Strike    1.0     1\n",
       "3        0      978  Counter-Strike Source    1.0     1\n",
       "4        0     1125          Day of Defeat    1.0     1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add user ID and item ID fields\n",
    "filtered_ratings['item_id'] = filtered_ratings['game'].astype('category').cat.codes\n",
    "filtered_ratings['user_id'] = filtered_ratings['user_id'].astype('category').cat.codes\n",
    "print(\"Total users:\", filtered_ratings.groupby(\"user_id\").sum(\"view\").shape[0])\n",
    "\n",
    "filtered_ratings = filtered_ratings[['user_id','item_id','game','hours','view']]\n",
    "filtered_ratings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkH0wLgv2zpy"
   },
   "source": [
    "Split dataset to 80% Train, 20% Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "C95yT3bsOnup",
    "outputId": "406ff43b-0dbe-4847-ff60-7614bae19157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test split: (92111, 5) (23028, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>hours</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31586.0</td>\n",
       "      <td>241.5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73720.0</td>\n",
       "      <td>585.5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172438.0</td>\n",
       "      <td>319.3</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14643.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14137.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>21611.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>23742.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>23184.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>10085.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>16364.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3757 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          item_id  hours  view\n",
       "user_id                       \n",
       "0         31586.0  241.5    17\n",
       "1         73720.0  585.5    29\n",
       "2        172438.0  319.3    65\n",
       "3         14643.0    8.0     8\n",
       "4         14137.0    6.0     6\n",
       "...           ...    ...   ...\n",
       "3752      21611.0    7.7     7\n",
       "3753      23742.0   27.8    11\n",
       "3754      23184.0   14.1     6\n",
       "3755      10085.0   10.0     6\n",
       "3756      16364.0   21.7     4\n",
       "\n",
       "[3757 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset in Train/Test\n",
    "train_df, test_df = train_test_split(filtered_ratings,\n",
    "                                                 stratify=filtered_ratings['user_id'], \n",
    "                                                 test_size=0.2,\n",
    "                                                 )  \n",
    "print(\"Train/test split:\", train_df.shape, test_df.shape)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "train_df.groupby(\"user_id\").sum('view')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVixq3Ji22JZ"
   },
   "source": [
    " Create a DataFrame with Content Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Itv7NSLQTJ7D",
    "outputId": "09ae164c-c489-4eba-e835-57d053f6720f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>game</th>\n",
       "      <th>total_users</th>\n",
       "      <th>total_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>007 Legends</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0RBITALIS</td>\n",
       "      <td>3</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1... 2... 3... KICK IT! (Drop That Beat Like a...</td>\n",
       "      <td>7</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10 Second Ninja</td>\n",
       "      <td>6</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10,000,000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>5108</td>\n",
       "      <td>sZone-Online</td>\n",
       "      <td>95</td>\n",
       "      <td>147.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5109</td>\n",
       "      <td>samurai_jazz</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>5110</td>\n",
       "      <td>the static speaks my name</td>\n",
       "      <td>13</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>5111</td>\n",
       "      <td>theHunter</td>\n",
       "      <td>220</td>\n",
       "      <td>515.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>5112</td>\n",
       "      <td>theHunter Primal</td>\n",
       "      <td>4</td>\n",
       "      <td>89.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5113 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                               game  total_users  \\\n",
       "0           0                                        007 Legends            1   \n",
       "1           1                                          0RBITALIS            3   \n",
       "2           2  1... 2... 3... KICK IT! (Drop That Beat Like a...            7   \n",
       "3           3                                    10 Second Ninja            6   \n",
       "4           4                                         10,000,000            1   \n",
       "...       ...                                                ...          ...   \n",
       "5108     5108                                       sZone-Online           95   \n",
       "5109     5109                                       samurai_jazz            1   \n",
       "5110     5110                          the static speaks my name           13   \n",
       "5111     5111                                          theHunter          220   \n",
       "5112     5112                                   theHunter Primal            4   \n",
       "\n",
       "      total_hours  \n",
       "0             1.7  \n",
       "1             4.2  \n",
       "2            27.0  \n",
       "3            11.9  \n",
       "4             4.6  \n",
       "...           ...  \n",
       "5108        147.7  \n",
       "5109          1.0  \n",
       "5110         15.0  \n",
       "5111        515.3  \n",
       "5112         89.9  \n",
       "\n",
       "[5113 rows x 4 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df = filtered_ratings.groupby(['game', 'item_id'])\\\n",
    "                                    .agg({'user_id': 'count', 'hours': np.sum})[['user_id','hours']]\\\n",
    "                                    .reset_index()\\\n",
    "                                    .rename(columns={'user_id': 'total_users', 'hours': 'total_hours'})\n",
    "\n",
    "\n",
    "games_df = games_df[['item_id', 'game','total_users','total_hours']]\n",
    "games_df      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJhKSA0SESJ4"
   },
   "source": [
    "### Create a Matrix of Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zBD8mrqYPpe",
    "outputId": "7c338b56-b628-4efa-a61e-13c60c4009fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set - users,items =  (3757, 4857)\n",
      "Test set - users,items =  (3757, 3230)\n"
     ]
    }
   ],
   "source": [
    "# Create a user-item matrix\n",
    "# For this dataset, we train a U-AutoRec since we only have item properties.\n",
    "\n",
    "users_items_matrix_train = train_df.pivot(index='user_id', columns='item_id', values='view').fillna(0)\n",
    "users_items_matrix_test  = test_df.pivot(index='user_id', columns='item_id', values='view').fillna(0)\n",
    "\n",
    "print(\"Train set - users,items = \", users_items_matrix_train.shape)\n",
    "print(\"Test set - users,items = \", users_items_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvYnw1g_6r4_",
    "outputId": "b6392bd1-04e0-46a9-ba01-84584045e189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set - users,items =  (3757, 4857)\n",
      "Test set - users,items =  (3757, 4857)\n"
     ]
    }
   ],
   "source": [
    "# Extend test set to account missing items, set default rating to 0\n",
    "for i in range(users_items_matrix_train.shape[1] - users_items_matrix_test.shape[1]):\n",
    "  users_items_matrix_test[users_items_matrix_test.shape[1] + users_items_matrix_test.shape[1]] = 0\n",
    "\n",
    "print(\"Train set - users,items = \", users_items_matrix_train.shape)\n",
    "print(\"Test set - users,items = \", users_items_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "C2_5DwQrbGuz",
    "outputId": "a3bdc1c1-3377-4170-b589-960bff78c83f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5100</th>\n",
       "      <th>5101</th>\n",
       "      <th>5102</th>\n",
       "      <th>5104</th>\n",
       "      <th>5105</th>\n",
       "      <th>5106</th>\n",
       "      <th>5108</th>\n",
       "      <th>5110</th>\n",
       "      <th>5111</th>\n",
       "      <th>5112</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 4857 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "user_id                                                              ...   \n",
       "0         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "6         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "7         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "8         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "9         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "item_id  5100  5101  5102  5104  5105  5106  5108  5110  5111  5112  \n",
       "user_id                                                              \n",
       "0         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "7         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "8         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "9         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[10 rows x 4857 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_items_matrix_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdNTZ4YxESJ6"
   },
   "source": [
    "### Create a Input Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "zRCO9j5yESJ6"
   },
   "outputs": [],
   "source": [
    "def split_str(val):\n",
    "    tokens = []\n",
    "    for v in val:\n",
    "        tokens.extend(v.split(' '))\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "N-Ju68k0ESJ7",
    "outputId": "a9e9123f-a6d2-4ec6-9a74-a10491266225"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>game</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Cities Skylines, Day of Defeat, Portal, Deus ...</td>\n",
       "      <td>Cities Skylines Day of Defeat Portal Deus Ex H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Arma 2, Age of Empires II HD Edition, Thief -...</td>\n",
       "      <td>Arma 2 Age of Empires II HD Edition Thief - Pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                               game  \\\n",
       "0        0  [Cities Skylines, Day of Defeat, Portal, Deus ...   \n",
       "1        1  [Arma 2, Age of Empires II HD Edition, Thief -...   \n",
       "\n",
       "                                              tokens  \n",
       "0  Cities Skylines Day of Defeat Portal Deus Ex H...  \n",
       "1  Arma 2 Age of Empires II HD Edition Thief - Pr...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group games per user\n",
    "user_games = train_df.groupby('user_id')['game'].apply(list).reset_index()\n",
    "user_games.head()\n",
    "\n",
    "# Split games names\n",
    "user_games['tokens'] = user_games['game'].apply(split_str)\n",
    "user_games.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "AAdnzyzXESJ7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (/home/sr-gpu/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-ef2a4f7bd7fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/backend/load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrictVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtranspose_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mpy_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (/home/sr-gpu/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py)"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ILkAmJZESJ7",
    "outputId": "c338c8c5-85e3-4038-86b7-1afcd8e6cb80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63, 55, 84, 94, 62, 15, 80, 49, 92, 99, 14, 67, 15, 12, 98, 99, 12, 9, 97, 98, 99, 12, 32, 14, 67, 54, 98, 99, 12, 72, 12, 98, 99, 12, 44, 79, 32, 95, 74, 29, 95, 98, 99, 30, 37, 98, 99, 12, 44, 1, 98, 99, 81, 93], [79, 12, 78, 94, 56, 51, 5, 18, 23, 15, 59, 91, 71, 14, 67, 54, 48, 94, 28, 59, 80, 12, 74, 29, 95, 5, 87, 79, 12, 35, 99, 9, 97, 14, 67, 46, 30, 48, 94, 28, 59, 80, 12, 68, 23, 17, 98, 99, 30, 37, 48, 94, 28, 59, 80, 50, 23, 59, 92, 7, 73, 94, 89, 19, 18, 23, 61, 98, 99, 56, 20, 6, 23, 82, 15, 12, 98, 99, 81, 93, 48, 94, 28, 59, 80, 50, 68, 55, 84, 94, 62, 23, 12, 77, 23, 71, 90]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "vocab_size   = 100\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in user_games.tokens]\n",
    "print(encoded_docs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0mlJ4eyESJ8",
    "outputId": "ccd62782-bd30-40f6-c1f3-736ef108cb64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62, 15, 80, ..., 99, 81, 93],\n",
       "       [99, 30, 37, ..., 23, 71, 90],\n",
       "       [78, 94, 56, ..., 12, 11, 87],\n",
       "       ...,\n",
       "       [ 4, 47, 39, ...,  0,  0,  0],\n",
       "       [60, 51, 28, ...,  0,  0,  0],\n",
       "       [49, 74, 29, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length  = 50\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "padded_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oLE3tfwESJ8"
   },
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "o8HwliXac-Kp"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "class BaseModel(object):\n",
    "  WEIGHT_MODEL       = \"weights-best-model.hdf5\"\n",
    "\n",
    "  def callbacks_list(self, monitor='val_loss', path_model = WEIGHT_MODEL, patience=15):\n",
    "    checkpoint = ModelCheckpoint(path_model, monitor=monitor, verbose=1, save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor=monitor,min_delta=0, patience=patience, verbose=0, mode='auto')\n",
    "\n",
    "    callbacks_list = [checkpoint, early_stop]\n",
    "    return callbacks_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "ZQPBpujwSOHm"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import add\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class AutoEncContentModel(BaseModel):\n",
    "  def __init__(self, layers = [], epochs = None, batch = None, \n",
    "                      activation = None, dropout = None, lr = None, reg = None):\n",
    "    self.layers  = layers\n",
    "    self.epochs  = epochs\n",
    "    self.batch   = batch\n",
    "    self.activation = activation\n",
    "    self.dropout = dropout\n",
    "    self.lr      = lr\n",
    "    self.reg     = reg\n",
    "    self.model   = None\n",
    "        \n",
    "\n",
    "  def data_preparation(self, interactions, user_item_matrix):\n",
    "    '''\n",
    "    Create a Input to Model\n",
    "    '''\n",
    "\n",
    "    # Params\n",
    "    #   integer encode the documents\n",
    "    vocab_size   = 100\n",
    "    #   pad documents to a max length of 4 words\n",
    "    max_length   = 50\n",
    "\n",
    "\n",
    "    def split_str(val):\n",
    "      '''\n",
    "      Split and Join Array(Array(str))\n",
    "      '''\n",
    "      tokens = []\n",
    "      for v in val:\n",
    "          tokens.extend(v.split(' '))\n",
    "      return ' '.join(tokens)\n",
    "\n",
    "    #  Order users in matrix interactions\n",
    "    users_ids  = list(user_item_matrix.index)\n",
    "    \n",
    "    # Dataset with User X Content information\n",
    "    user_games = interactions.groupby('user_id')['game'].apply(list).loc[users_ids].reset_index()\n",
    "    user_games['tokens'] = user_games['game'].apply(split_str)\n",
    "\n",
    "    # Prepare input layer\n",
    "    encoded_tokens = [one_hot(d, vocab_size) for d in user_games.tokens]\n",
    "    padded_tokens  = pad_sequences(encoded_tokens, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Input  \n",
    "    X = [user_item_matrix.values, padded_tokens]\n",
    "    y = user_item_matrix.values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "  def compute_masked_loss(self, y_true, y_pred):\n",
    "      \"\"\"\n",
    "      Compute loss between y_true(The true output) and y_pred(The predicted output)\n",
    "      \"\"\"\n",
    "      # ignore the missing value (having value of zero) in loss computation\n",
    "      mask_true = tf.cast(tf.not_equal(y_true, 0), dtype='float32') \n",
    "\n",
    "      error = y_true - y_pred\n",
    "\n",
    "      se = tf.square(error) * mask_true\n",
    "      mse = tf.reduce_sum(se) / tf.reduce_sum(mask_true)\n",
    "      return mse \n",
    "\n",
    "  def masked_rmse_loss(self, y_true, y_pred):\n",
    "      return tf.math.sqrt(self.compute_masked_loss(y_true, y_pred))\n",
    "\n",
    "  def fit(self, X, y, verbose=1):\n",
    "    '''\n",
    "    Train Model\n",
    "    '''\n",
    "\n",
    "    # Build model\n",
    "    model = self.build_model(X)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr=self.lr), \n",
    "                    loss=self.compute_masked_loss, metrics=[self.masked_rmse_loss])\n",
    "\n",
    "    # train\n",
    "    hist = model.fit(x=X, y=y,\n",
    "                      epochs=self.epochs,\n",
    "                      batch_size=self.batch,\n",
    "                      shuffle=True,\n",
    "                      validation_split=0.1,\n",
    "                      callbacks=self.callbacks_list(), verbose=verbose)\n",
    "\n",
    "    model.load_weights(self.WEIGHT_MODEL)\n",
    "    self.model = model\n",
    "    self.history = hist\n",
    "\n",
    "    return model, hist\n",
    "\n",
    "  def plot_loss_history(self):\n",
    "    plt.plot(self.history.history['loss'])\n",
    "    plt.plot(self.history.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "  def predict(self, X):\n",
    "\n",
    "    # Predict\n",
    "    pred = self.model.predict(X)\n",
    "\n",
    "    # remove watched items from predictions\n",
    "    pred = pred * (X[0] == 0) \n",
    "\n",
    "    return pred\n",
    "\n",
    "  def build_model(self, X):\n",
    "    '''\n",
    "    Autoencoder for Collaborative Filter Model\n",
    "    '''\n",
    "\n",
    "    # Params\n",
    "    users_items_matrix, content_info = X\n",
    "\n",
    "    # Input\n",
    "    input_layer   = x = Input(shape=(users_items_matrix.shape[1],), name='UserScore')\n",
    "    input_content = Input(shape=(content_info.shape[1],), name='Itemcontent')\n",
    "\n",
    "    # Encoder\n",
    "    k = int(len(self.layers)/2)\n",
    "    i = 0\n",
    "    for l in self.layers[:k]:\n",
    "      x = Dense(l, activation=self.activation, \n",
    "                      name='EncLayer{}'.format(i))(x)\n",
    "      i = i+1\n",
    "\n",
    "    # Latent Space\n",
    "    x = Dense(self.layers[k], activation=self.activation, \n",
    "                                name='UserLatentSpace')(x)\n",
    "\n",
    "    # Content Information\n",
    "    x_content = Embedding(100, self.layers[k], \n",
    "                        input_length=content_info.shape[1])(input_content)\n",
    "    x_content = Flatten()(x_content)\n",
    "    x_content = Dense(self.layers[k], activation=self.activation, \n",
    "                                name='ItemLatentSpace')(x_content)\n",
    "    # Concatenate\n",
    "    x = add([x, x_content], name='LatentSpace')\n",
    "\n",
    "    # Dropout\n",
    "    x = Dropout(self.dropout)(x)\n",
    "\n",
    "    # Decoder\n",
    "    for l in self.layers[k+1:]:\n",
    "      i = i-1\n",
    "      x = Dense(l, activation=self.activation, \n",
    "                      name='DecLayer{}'.format(i))(x)\n",
    "\n",
    "    # Output\n",
    "    output_layer = Dense(users_items_matrix.shape[1], activation='linear', name='UserScorePred')(x)\n",
    "\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    model = Model([input_layer, input_content], output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Orsa05gb82jQ"
   },
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "L_f2CI1ufSYD"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "layers = [128, 256, 512]\n",
    "epochs = 10\n",
    "batch = 128\n",
    "activation = 'sigmoid'         #['relu', 'elu', 'selu', 'sigmoid']\n",
    "dropout = 0.6\n",
    "lr = 0.001\n",
    "reg = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnagqF9TESJ-",
    "outputId": "86297091-4178-4b82-ec02-5e6d09201941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 10ms/step - loss: 0.1737 - masked_rmse_loss: 0.3656 - val_loss: 0.0216 - val_masked_rmse_loss: 0.1466\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02158, saving model to weights-best-model.hdf5\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0115 - masked_rmse_loss: 0.1054 - val_loss: 0.0110 - val_masked_rmse_loss: 0.1040\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02158 to 0.01103, saving model to weights-best-model.hdf5\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0054 - masked_rmse_loss: 0.0731 - val_loss: 0.0091 - val_masked_rmse_loss: 0.0944\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01103 to 0.00914, saving model to weights-best-model.hdf5\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0040 - masked_rmse_loss: 0.0632 - val_loss: 0.0081 - val_masked_rmse_loss: 0.0886\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00914 to 0.00809, saving model to weights-best-model.hdf5\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0035 - masked_rmse_loss: 0.0591 - val_loss: 0.0081 - val_masked_rmse_loss: 0.0884\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00809 to 0.00806, saving model to weights-best-model.hdf5\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0033 - masked_rmse_loss: 0.0576 - val_loss: 0.0080 - val_masked_rmse_loss: 0.0882\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00806 to 0.00804, saving model to weights-best-model.hdf5\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0031 - masked_rmse_loss: 0.0558 - val_loss: 0.0081 - val_masked_rmse_loss: 0.0888\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00804\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0031 - masked_rmse_loss: 0.0556 - val_loss: 0.0084 - val_masked_rmse_loss: 0.0901\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00804\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0030 - masked_rmse_loss: 0.0547 - val_loss: 0.0084 - val_masked_rmse_loss: 0.0903\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00804\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0033 - masked_rmse_loss: 0.0569 - val_loss: 0.0094 - val_masked_rmse_loss: 0.0962\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00804\n",
      "Model: \"model_112\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Itemcontent (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "UserScore (InputLayer)          [(None, 4857)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_112 (Embedding)       (None, 50, 256)      25600       Itemcontent[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "EncLayer0 (Dense)               (None, 128)          621824      UserScore[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_112 (Flatten)           (None, 12800)        0           embedding_112[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "UserLatentSpace (Dense)         (None, 256)          33024       EncLayer0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ItemLatentSpace (Dense)         (None, 256)          3277056     flatten_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LatentSpace (Add)               (None, 256)          0           UserLatentSpace[0][0]            \n",
      "                                                                 ItemLatentSpace[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 256)          0           LatentSpace[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "DecLayer0 (Dense)               (None, 512)          131584      dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "UserScorePred (Dense)           (None, 4857)         2491641     DecLayer0[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,580,729\n",
      "Trainable params: 6,580,729\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "autoenc_model = AutoEncContentModel(layers, epochs, batch, activation, dropout, lr, reg)\n",
    "# ---------------------------------------------\n",
    "# Input - Prepare input layer\n",
    "X, y  = autoenc_model.data_preparation(train_df, users_items_matrix_train)\n",
    "\n",
    "# Train\n",
    "model, hist = autoenc_model.fit(X, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "IAP2QP8Q4Gr7",
    "outputId": "1fd5f7e4-2a79-4812-ca08-ef684036eead"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "HB3dHF5a5Cz-",
    "outputId": "2f688161-b163-4317-e6b5-1012b5df4bf6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoenc_model.plot_loss_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OwZtfB_56Mc",
    "outputId": "94351670-087a-46b0-ed48-d9e25af2e857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE on train: 0.05689087137579918\n",
      "Model RMSE on validation: 0.0961882546544075\n"
     ]
    }
   ],
   "source": [
    "print(\"Model RMSE on train:\", autoenc_model.history.history['masked_rmse_loss'][-1])\n",
    "print(\"Model RMSE on validation:\", autoenc_model.history.history['val_masked_rmse_loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d6eSBkG77Ez"
   },
   "source": [
    "## Model Evaluation on test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44dYKay05-Tf",
    "outputId": "11dc40d9-6ae3-4931-f894-fb4b2e8a52b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3757, 4857) (3757, 50) (3757, 4857)\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.0072 - masked_rmse_loss: 0.0817\n",
      "Model RMSE on test set: 0.08171898871660233\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test  = autoenc_model.data_preparation(test_df, users_items_matrix_test)\n",
    "print(X_test[0].shape, X_test[1].shape, y_test.shape)\n",
    "test_rmse = model.evaluate(X_test, y_test)[1]\n",
    "print(\"Model RMSE on test set:\", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "c6gbicU0ESKA"
   },
   "outputs": [],
   "source": [
    "# Predict new Matrix Interactions, set score zero on visualized games\n",
    "predicted_test = model.predict(X_test) * (X_test[0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x0ZqP0r2JSJD",
    "outputId": "2d0e9774-8345-4f46-b78c-3ae2bd6b96f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92776424, 1.0502156 , 0.9587581 , ..., 0.9912087 , 0.9830445 ,\n",
       "        1.0541272 ],\n",
       "       [0.9243959 , 1.0470518 , 0.95303214, ..., 0.9870202 , 0.98227173,\n",
       "        1.0516173 ],\n",
       "       [0.91410595, 1.0371462 , 0.93205607, ..., 0.96879464, 0.9709455 ,\n",
       "        1.0394546 ],\n",
       "       ...,\n",
       "       [0.9229688 , 1.0453271 , 0.9486071 , ..., 0.9829616 , 0.9780255 ,\n",
       "        1.0475434 ],\n",
       "       [0.92351216, 1.0459615 , 0.94938546, ..., 0.98358864, 0.9783038 ,\n",
       "        1.0479836 ],\n",
       "       [0.92583454, 1.0482444 , 0.95390964, ..., 0.9873502 , 0.98046297,\n",
       "        1.0508267 ]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "aLqnREVCESKA",
    "outputId": "ac0071ee-634c-43bd-fb7a-d786391368cc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6b9e2cbd-0fa3-47ef-935c-e70bb62cb2fc\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>19</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>57</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>...</th>\n",
       "      <th>9626</th>\n",
       "      <th>9628</th>\n",
       "      <th>9630</th>\n",
       "      <th>9632</th>\n",
       "      <th>9634</th>\n",
       "      <th>9636</th>\n",
       "      <th>9638</th>\n",
       "      <th>9640</th>\n",
       "      <th>9642</th>\n",
       "      <th>9644</th>\n",
       "      <th>9646</th>\n",
       "      <th>9648</th>\n",
       "      <th>9650</th>\n",
       "      <th>9652</th>\n",
       "      <th>9654</th>\n",
       "      <th>9656</th>\n",
       "      <th>9658</th>\n",
       "      <th>9660</th>\n",
       "      <th>9662</th>\n",
       "      <th>9664</th>\n",
       "      <th>9666</th>\n",
       "      <th>9668</th>\n",
       "      <th>9670</th>\n",
       "      <th>9672</th>\n",
       "      <th>9674</th>\n",
       "      <th>9676</th>\n",
       "      <th>9678</th>\n",
       "      <th>9680</th>\n",
       "      <th>9682</th>\n",
       "      <th>9684</th>\n",
       "      <th>9686</th>\n",
       "      <th>9688</th>\n",
       "      <th>9690</th>\n",
       "      <th>9692</th>\n",
       "      <th>9694</th>\n",
       "      <th>9696</th>\n",
       "      <th>9698</th>\n",
       "      <th>9700</th>\n",
       "      <th>9702</th>\n",
       "      <th>9704</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.927764</td>\n",
       "      <td>1.050216</td>\n",
       "      <td>0.958758</td>\n",
       "      <td>0.987254</td>\n",
       "      <td>0.955157</td>\n",
       "      <td>0.926381</td>\n",
       "      <td>0.941446</td>\n",
       "      <td>1.025791</td>\n",
       "      <td>1.019737</td>\n",
       "      <td>1.014245</td>\n",
       "      <td>1.022758</td>\n",
       "      <td>1.169381</td>\n",
       "      <td>1.015265</td>\n",
       "      <td>0.977669</td>\n",
       "      <td>0.990057</td>\n",
       "      <td>0.976444</td>\n",
       "      <td>1.054010</td>\n",
       "      <td>1.002969</td>\n",
       "      <td>0.972085</td>\n",
       "      <td>1.005751</td>\n",
       "      <td>1.085900</td>\n",
       "      <td>1.151219</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>0.900567</td>\n",
       "      <td>1.017312</td>\n",
       "      <td>1.172406</td>\n",
       "      <td>0.996391</td>\n",
       "      <td>1.065961</td>\n",
       "      <td>1.130077</td>\n",
       "      <td>1.001131</td>\n",
       "      <td>0.869063</td>\n",
       "      <td>0.990930</td>\n",
       "      <td>0.930400</td>\n",
       "      <td>1.050629</td>\n",
       "      <td>0.994277</td>\n",
       "      <td>1.044856</td>\n",
       "      <td>-0.050224</td>\n",
       "      <td>1.017572</td>\n",
       "      <td>0.989605</td>\n",
       "      <td>0.983671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956288</td>\n",
       "      <td>0.808496</td>\n",
       "      <td>1.111012</td>\n",
       "      <td>1.015892</td>\n",
       "      <td>0.986194</td>\n",
       "      <td>0.988156</td>\n",
       "      <td>1.016201</td>\n",
       "      <td>1.015155</td>\n",
       "      <td>1.036307</td>\n",
       "      <td>0.952423</td>\n",
       "      <td>1.202374</td>\n",
       "      <td>0.979591</td>\n",
       "      <td>0.747436</td>\n",
       "      <td>1.213020</td>\n",
       "      <td>1.169414</td>\n",
       "      <td>1.027662</td>\n",
       "      <td>0.937783</td>\n",
       "      <td>0.949462</td>\n",
       "      <td>0.990186</td>\n",
       "      <td>1.001271</td>\n",
       "      <td>0.965187</td>\n",
       "      <td>0.872155</td>\n",
       "      <td>0.977719</td>\n",
       "      <td>0.971915</td>\n",
       "      <td>1.000601</td>\n",
       "      <td>1.053965</td>\n",
       "      <td>0.133448</td>\n",
       "      <td>0.903565</td>\n",
       "      <td>0.857393</td>\n",
       "      <td>1.042702</td>\n",
       "      <td>1.051690</td>\n",
       "      <td>1.072167</td>\n",
       "      <td>0.876584</td>\n",
       "      <td>0.989459</td>\n",
       "      <td>1.137278</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.249123</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.983045</td>\n",
       "      <td>1.054127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.924396</td>\n",
       "      <td>1.047052</td>\n",
       "      <td>0.953032</td>\n",
       "      <td>0.981666</td>\n",
       "      <td>0.950446</td>\n",
       "      <td>0.924505</td>\n",
       "      <td>0.936499</td>\n",
       "      <td>1.022768</td>\n",
       "      <td>1.016094</td>\n",
       "      <td>1.011029</td>\n",
       "      <td>1.017512</td>\n",
       "      <td>1.164794</td>\n",
       "      <td>1.009426</td>\n",
       "      <td>0.974993</td>\n",
       "      <td>0.986512</td>\n",
       "      <td>0.973870</td>\n",
       "      <td>1.050616</td>\n",
       "      <td>1.001097</td>\n",
       "      <td>0.967820</td>\n",
       "      <td>1.003782</td>\n",
       "      <td>1.083359</td>\n",
       "      <td>1.148043</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>1.013402</td>\n",
       "      <td>1.169604</td>\n",
       "      <td>0.994358</td>\n",
       "      <td>1.062085</td>\n",
       "      <td>1.122902</td>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.867156</td>\n",
       "      <td>0.988398</td>\n",
       "      <td>0.929183</td>\n",
       "      <td>1.049054</td>\n",
       "      <td>0.991272</td>\n",
       "      <td>1.039586</td>\n",
       "      <td>-0.049691</td>\n",
       "      <td>1.014963</td>\n",
       "      <td>0.989058</td>\n",
       "      <td>0.980279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951608</td>\n",
       "      <td>0.805452</td>\n",
       "      <td>1.107897</td>\n",
       "      <td>1.009832</td>\n",
       "      <td>0.982365</td>\n",
       "      <td>0.986821</td>\n",
       "      <td>1.013000</td>\n",
       "      <td>1.009574</td>\n",
       "      <td>1.033265</td>\n",
       "      <td>0.950602</td>\n",
       "      <td>1.198155</td>\n",
       "      <td>0.973210</td>\n",
       "      <td>0.744880</td>\n",
       "      <td>1.209344</td>\n",
       "      <td>1.165563</td>\n",
       "      <td>1.023173</td>\n",
       "      <td>0.936274</td>\n",
       "      <td>0.942125</td>\n",
       "      <td>0.986702</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>0.960247</td>\n",
       "      <td>0.868786</td>\n",
       "      <td>0.973190</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.996302</td>\n",
       "      <td>1.051544</td>\n",
       "      <td>0.133410</td>\n",
       "      <td>0.900882</td>\n",
       "      <td>0.857983</td>\n",
       "      <td>1.040450</td>\n",
       "      <td>1.049628</td>\n",
       "      <td>1.066976</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>0.983425</td>\n",
       "      <td>1.133886</td>\n",
       "      <td>0.984712</td>\n",
       "      <td>0.248440</td>\n",
       "      <td>0.987020</td>\n",
       "      <td>0.982272</td>\n",
       "      <td>1.051617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.914106</td>\n",
       "      <td>1.037146</td>\n",
       "      <td>0.932056</td>\n",
       "      <td>0.962204</td>\n",
       "      <td>0.931833</td>\n",
       "      <td>0.912215</td>\n",
       "      <td>0.918417</td>\n",
       "      <td>1.006115</td>\n",
       "      <td>0.998659</td>\n",
       "      <td>0.997509</td>\n",
       "      <td>0.993660</td>\n",
       "      <td>1.143093</td>\n",
       "      <td>0.994759</td>\n",
       "      <td>0.958433</td>\n",
       "      <td>0.972776</td>\n",
       "      <td>0.957486</td>\n",
       "      <td>1.033562</td>\n",
       "      <td>0.989510</td>\n",
       "      <td>0.950486</td>\n",
       "      <td>0.992884</td>\n",
       "      <td>1.068309</td>\n",
       "      <td>1.136460</td>\n",
       "      <td>0.962373</td>\n",
       "      <td>0.875878</td>\n",
       "      <td>0.999131</td>\n",
       "      <td>1.153797</td>\n",
       "      <td>0.983267</td>\n",
       "      <td>1.043265</td>\n",
       "      <td>1.100025</td>\n",
       "      <td>0.981486</td>\n",
       "      <td>0.854636</td>\n",
       "      <td>0.978669</td>\n",
       "      <td>0.918458</td>\n",
       "      <td>1.039885</td>\n",
       "      <td>0.981284</td>\n",
       "      <td>1.017017</td>\n",
       "      <td>-0.045893</td>\n",
       "      <td>0.999801</td>\n",
       "      <td>0.981895</td>\n",
       "      <td>0.961992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935764</td>\n",
       "      <td>0.792829</td>\n",
       "      <td>1.097207</td>\n",
       "      <td>0.987028</td>\n",
       "      <td>0.968660</td>\n",
       "      <td>0.979105</td>\n",
       "      <td>0.998271</td>\n",
       "      <td>0.993108</td>\n",
       "      <td>1.014002</td>\n",
       "      <td>0.943860</td>\n",
       "      <td>1.177677</td>\n",
       "      <td>0.947763</td>\n",
       "      <td>0.733083</td>\n",
       "      <td>1.192194</td>\n",
       "      <td>1.149241</td>\n",
       "      <td>1.008462</td>\n",
       "      <td>0.927929</td>\n",
       "      <td>0.920986</td>\n",
       "      <td>0.976234</td>\n",
       "      <td>0.984470</td>\n",
       "      <td>0.938170</td>\n",
       "      <td>0.852324</td>\n",
       "      <td>0.953319</td>\n",
       "      <td>0.961770</td>\n",
       "      <td>0.981321</td>\n",
       "      <td>1.037935</td>\n",
       "      <td>0.135402</td>\n",
       "      <td>0.889814</td>\n",
       "      <td>0.855542</td>\n",
       "      <td>1.025215</td>\n",
       "      <td>1.033208</td>\n",
       "      <td>1.048156</td>\n",
       "      <td>0.857209</td>\n",
       "      <td>0.959135</td>\n",
       "      <td>1.116616</td>\n",
       "      <td>0.969218</td>\n",
       "      <td>0.240347</td>\n",
       "      <td>0.968795</td>\n",
       "      <td>0.970945</td>\n",
       "      <td>1.039455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.924842</td>\n",
       "      <td>1.047369</td>\n",
       "      <td>0.951936</td>\n",
       "      <td>0.980853</td>\n",
       "      <td>0.949314</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>0.936248</td>\n",
       "      <td>1.021360</td>\n",
       "      <td>1.014457</td>\n",
       "      <td>1.009832</td>\n",
       "      <td>1.015600</td>\n",
       "      <td>1.164068</td>\n",
       "      <td>1.008858</td>\n",
       "      <td>0.972811</td>\n",
       "      <td>0.985832</td>\n",
       "      <td>0.972523</td>\n",
       "      <td>1.048627</td>\n",
       "      <td>0.999775</td>\n",
       "      <td>0.967465</td>\n",
       "      <td>1.002631</td>\n",
       "      <td>1.082270</td>\n",
       "      <td>1.146972</td>\n",
       "      <td>0.974879</td>\n",
       "      <td>0.895071</td>\n",
       "      <td>1.012656</td>\n",
       "      <td>1.167805</td>\n",
       "      <td>0.992631</td>\n",
       "      <td>1.060717</td>\n",
       "      <td>1.123078</td>\n",
       "      <td>0.996161</td>\n",
       "      <td>0.865605</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.926658</td>\n",
       "      <td>1.047927</td>\n",
       "      <td>0.991132</td>\n",
       "      <td>1.038124</td>\n",
       "      <td>-0.049398</td>\n",
       "      <td>1.012679</td>\n",
       "      <td>0.987415</td>\n",
       "      <td>0.978871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951368</td>\n",
       "      <td>0.805003</td>\n",
       "      <td>1.106999</td>\n",
       "      <td>1.009061</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.986503</td>\n",
       "      <td>1.012256</td>\n",
       "      <td>1.009733</td>\n",
       "      <td>1.030403</td>\n",
       "      <td>0.949722</td>\n",
       "      <td>1.195667</td>\n",
       "      <td>0.971101</td>\n",
       "      <td>0.744213</td>\n",
       "      <td>1.208350</td>\n",
       "      <td>1.165162</td>\n",
       "      <td>1.022479</td>\n",
       "      <td>0.935783</td>\n",
       "      <td>0.942555</td>\n",
       "      <td>0.986828</td>\n",
       "      <td>0.998087</td>\n",
       "      <td>0.959345</td>\n",
       "      <td>0.867871</td>\n",
       "      <td>0.971040</td>\n",
       "      <td>0.969762</td>\n",
       "      <td>0.995418</td>\n",
       "      <td>1.050069</td>\n",
       "      <td>0.133466</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.856425</td>\n",
       "      <td>1.038848</td>\n",
       "      <td>1.047784</td>\n",
       "      <td>1.066240</td>\n",
       "      <td>0.871745</td>\n",
       "      <td>0.982405</td>\n",
       "      <td>1.132379</td>\n",
       "      <td>0.985037</td>\n",
       "      <td>0.247169</td>\n",
       "      <td>0.985993</td>\n",
       "      <td>0.979335</td>\n",
       "      <td>1.049911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.924053</td>\n",
       "      <td>1.046697</td>\n",
       "      <td>0.951801</td>\n",
       "      <td>0.980270</td>\n",
       "      <td>0.948741</td>\n",
       "      <td>0.921355</td>\n",
       "      <td>0.935078</td>\n",
       "      <td>1.020685</td>\n",
       "      <td>1.013510</td>\n",
       "      <td>1.009561</td>\n",
       "      <td>1.015264</td>\n",
       "      <td>1.162634</td>\n",
       "      <td>1.008995</td>\n",
       "      <td>0.972295</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.971731</td>\n",
       "      <td>1.048319</td>\n",
       "      <td>0.999015</td>\n",
       "      <td>0.966429</td>\n",
       "      <td>1.002274</td>\n",
       "      <td>1.081575</td>\n",
       "      <td>1.146006</td>\n",
       "      <td>0.973861</td>\n",
       "      <td>0.894356</td>\n",
       "      <td>1.011762</td>\n",
       "      <td>1.167139</td>\n",
       "      <td>0.991495</td>\n",
       "      <td>1.059796</td>\n",
       "      <td>1.121839</td>\n",
       "      <td>0.995361</td>\n",
       "      <td>0.865115</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.926179</td>\n",
       "      <td>1.047601</td>\n",
       "      <td>0.990206</td>\n",
       "      <td>1.036800</td>\n",
       "      <td>-0.048960</td>\n",
       "      <td>1.012236</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>0.978259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950205</td>\n",
       "      <td>0.804655</td>\n",
       "      <td>1.106584</td>\n",
       "      <td>1.008499</td>\n",
       "      <td>0.981002</td>\n",
       "      <td>0.986213</td>\n",
       "      <td>1.011518</td>\n",
       "      <td>1.008849</td>\n",
       "      <td>1.030281</td>\n",
       "      <td>0.949519</td>\n",
       "      <td>1.194559</td>\n",
       "      <td>0.969725</td>\n",
       "      <td>0.743282</td>\n",
       "      <td>1.207221</td>\n",
       "      <td>1.164692</td>\n",
       "      <td>1.021556</td>\n",
       "      <td>0.935557</td>\n",
       "      <td>0.941560</td>\n",
       "      <td>0.985902</td>\n",
       "      <td>0.997443</td>\n",
       "      <td>0.958304</td>\n",
       "      <td>0.867092</td>\n",
       "      <td>0.969607</td>\n",
       "      <td>0.969093</td>\n",
       "      <td>0.995418</td>\n",
       "      <td>1.049286</td>\n",
       "      <td>0.133259</td>\n",
       "      <td>0.900115</td>\n",
       "      <td>0.856395</td>\n",
       "      <td>1.038481</td>\n",
       "      <td>1.046774</td>\n",
       "      <td>1.065542</td>\n",
       "      <td>0.871345</td>\n",
       "      <td>0.981486</td>\n",
       "      <td>1.131730</td>\n",
       "      <td>0.984602</td>\n",
       "      <td>0.247005</td>\n",
       "      <td>0.985177</td>\n",
       "      <td>0.979273</td>\n",
       "      <td>1.049653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4853 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b9e2cbd-0fa3-47ef-935c-e70bb62cb2fc')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6b9e2cbd-0fa3-47ef-935c-e70bb62cb2fc button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6b9e2cbd-0fa3-47ef-935c-e70bb62cb2fc');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "item_id      2         3         5     ...      9700      9702      9704\n",
       "user_id                                ...                              \n",
       "0        0.927764  1.050216  0.958758  ...  0.991209  0.983045  1.054127\n",
       "1        0.924396  1.047052  0.953032  ...  0.987020  0.982272  1.051617\n",
       "2        0.914106  1.037146  0.932056  ...  0.968795  0.970945  1.039455\n",
       "3        0.924842  1.047369  0.951936  ...  0.985993  0.979335  1.049911\n",
       "4        0.924053  1.046697  0.951801  ...  0.985177  0.979273  1.049653\n",
       "\n",
       "[5 rows x 4853 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the reconstructed matrix back to a Pandas dataframe\n",
    "predicted_users_items_matrix = pd.DataFrame(predicted_test, \n",
    "                                          columns = users_items_matrix_test.columns, \n",
    "                                          index   = users_items_matrix_test.index)\n",
    "predicted_users_items_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wAydtpdESKB",
    "outputId": "368ac266-49be-4ad5-a622-39e9996231ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG score: 0.12635963761223631\n"
     ]
    }
   ],
   "source": [
    "print(\"NDCG score:\", ndcg_score(users_items_matrix_test, predicted_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O24IG6-MT8_9"
   },
   "source": [
    "# Test data on MovieLens 1M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDazwuPXUYn4"
   },
   "source": [
    "## Download and load MovieLens 1M dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "ALBqHQqXUF-f"
   },
   "outputs": [],
   "source": [
    "import requests, zipfile, os\n",
    "url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
    "zip_name = 'ml-1m.zip'\n",
    "data_dir = 'ml-1m/'\n",
    "if not os.path.exists(os.path.join(data_dir, zip_name)):\n",
    "  r = requests.get(url, allow_redirects=True)\n",
    "  open(zip_name, 'wb').write(r.content)\n",
    "\n",
    "  with zipfile.ZipFile(zip_name,\"r\") as zip_ref:\n",
    "      zip_ref.extractall()\n",
    "\n",
    "cols_data = ['user_id','item_id','rating','timestamp']\n",
    "cols_user = ['user_id','gender', 'age','occupation','zipcode']\n",
    "cols_item = ['movie_id','movie_title', 'release_date','video_release_date',\n",
    "             'IMDb_URL','unknown','Action','Adventure','Animation',\n",
    "             'Childrens','Comedy','Crime','Documentary','Drama','Fantasy','Film_Noir','Horror','Musical','Mystery','Romance',\n",
    "             'Sci_Fi','Thriller','War','Western']\n",
    "\n",
    "\n",
    "# loading the data to dataframes\n",
    "df_users = pd.read_csv(data_dir + 'users.dat',delimiter='::', header=None,names=cols_user)\n",
    "df_ratings = pd.read_csv(data_dir + 'ratings.dat', delimiter='::', header=None, names=cols_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "Yyq4Hc12Y_qq"
   },
   "outputs": [],
   "source": [
    "# Age group dictionary retrieved from dataset description\n",
    "age_group_dict = {\n",
    "    1:  \"Under 18\",\n",
    "    18:  \"18-24\",\n",
    "    25:  \"25-34\",\n",
    "    35:  \"35-44\",\n",
    "    45:  \"45-49\",\n",
    "    50:  \"50-55\",\n",
    "    56:  \"56+\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "CJyZAYc9ZERV"
   },
   "outputs": [],
   "source": [
    "# Occupation dictionary retrieved from dataset description\n",
    "occupation_dict = {\n",
    "    0:  \"other or not specified\",\n",
    "    1:  \"academic/educator\",\n",
    "    2:  \"artist\",\n",
    "    3:  \"clerical/admin\",\n",
    "    4:  \"college/grad student\",\n",
    "    5:  \"customer service\",\n",
    "    6:  \"doctor/health care\",\n",
    "    7:  \"executive/managerial\",\n",
    "    8:  \"farmer\",\n",
    "    9:  \"homemaker\",\n",
    "    10:  \"K-12 student\",\n",
    "    11:  \"lawyer\",\n",
    "    12:  \"programmer\",\n",
    "    13:  \"retired\",\n",
    "    14:  \"sales/marketing\",\n",
    "    15:  \"scientist\",\n",
    "    16:  \"self-employed\",\n",
    "    17:  \"technician/engineer\",\n",
    "    18:  \"tradesman/craftsman\",\n",
    "    19:  \"unemployed\",\n",
    "    20:  \"writer\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "qERJFtRbeHL6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "JZthf8f8eI7N"
   },
   "outputs": [],
   "source": [
    "gender_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dahuDyGeJHj",
    "outputId": "516a8d32-6236-4942-d8ae-2f92fb0c94b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_encoder.fit(df_users['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "mCBIryVtefdU"
   },
   "outputs": [],
   "source": [
    "gender_values = gender_encoder.transform(df_users['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ND4oAG8be8G2",
    "outputId": "c4715b62-2d0c-43a5-e01e-e863d928dd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Encoding: [0 1 1 1 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"After Encoding:\", gender_values[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5gf4M3qb2FR",
    "outputId": "3f9fc00d-4dda-4493-d0f8-89153de73883"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  1],\n",
       "       [16, 56],\n",
       "       [15, 25],\n",
       "       ...,\n",
       "       [ 1, 56],\n",
       "       [ 0, 45],\n",
       "       [ 6, 25]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users[['occupation', 'age']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "R8y2sjSZb1TE",
    "outputId": "6bf6bdca-1c97-4dcf-90ae-ebbcd48acdde"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating  timestamp\n",
       "0              1     1193       5  978300760\n",
       "1              1      661       3  978302109\n",
       "2              1      914       3  978301968\n",
       "3              1     3408       4  978300275\n",
       "4              1     2355       5  978824291\n",
       "...          ...      ...     ...        ...\n",
       "1000204     6040     1091       1  956716541\n",
       "1000205     6040     1094       5  956704887\n",
       "1000206     6040      562       5  956704746\n",
       "1000207     6040     1096       4  956715648\n",
       "1000208     6040     1097       4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "faT2an1MUtok",
    "outputId": "6fe5ef3b-d545-4d2a-a30e-4f3e7732a426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800167, 4) (200042, 4)\n"
     ]
    }
   ],
   "source": [
    "#Split Train/Test\n",
    "df_ratings_train, df_ratings_test = train_test_split(df_ratings,\n",
    "                                                     stratify=df_ratings['user_id'],\n",
    "                                                     test_size=0.2)\n",
    "\n",
    "print(df_ratings_train.shape, df_ratings_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYbj5aEGU0W3",
    "outputId": "7ac88541-fbb0-415b-9175-e5c445304988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test: (3676, 6040) (3459, 6040)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy matrix\n",
    "\n",
    "# We want to train IAutoRec, so we build a movie-user matrix\n",
    "\n",
    "ratings_train = df_ratings_train.pivot(index='item_id', columns='user_id', values='rating').fillna(0)\n",
    "ratings_test = df_ratings_test.pivot(index='item_id', columns='user_id', values='rating').fillna(0)\n",
    "\n",
    "\n",
    "ratings_train = ratings_train.to_numpy()\n",
    "ratings_test = ratings_test.to_numpy()\n",
    "\n",
    "print(\"Train/test:\", ratings_train.shape, ratings_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "pmxB4tBnjPHP"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "layers = [128, 256, 512]\n",
    "epochs = 10\n",
    "batch = 128\n",
    "activation = 'sigmoid'         #['relu', 'elu', 'selu', 'sigmoid']\n",
    "dropout = 0.6\n",
    "lr = 0.001\n",
    "reg = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wphLhMzyjR4U",
    "outputId": "d2f24905-02b0-459d-afd3-106f6de4bcce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 3.8573 - masked_rmse_loss: 1.7888 - val_loss: 1.3121 - val_masked_rmse_loss: 1.1467\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.31213, saving model to weights-best-model.hdf5\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.2076 - masked_rmse_loss: 1.0973 - val_loss: 1.2551 - val_masked_rmse_loss: 1.1213\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.31213 to 1.25514, saving model to weights-best-model.hdf5\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0804 - masked_rmse_loss: 1.0392 - val_loss: 1.1738 - val_masked_rmse_loss: 1.0845\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25514 to 1.17377, saving model to weights-best-model.hdf5\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0313 - masked_rmse_loss: 1.0154 - val_loss: 1.1351 - val_masked_rmse_loss: 1.0667\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.17377 to 1.13512, saving model to weights-best-model.hdf5\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9797 - masked_rmse_loss: 0.9898 - val_loss: 1.0730 - val_masked_rmse_loss: 1.0371\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.13512 to 1.07295, saving model to weights-best-model.hdf5\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9422 - masked_rmse_loss: 0.9704 - val_loss: 1.0545 - val_masked_rmse_loss: 1.0279\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.07295 to 1.05453, saving model to weights-best-model.hdf5\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9065 - masked_rmse_loss: 0.9520 - val_loss: 1.0187 - val_masked_rmse_loss: 1.0103\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.05453 to 1.01869, saving model to weights-best-model.hdf5\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8789 - masked_rmse_loss: 0.9374 - val_loss: 0.9823 - val_masked_rmse_loss: 0.9922\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.01869 to 0.98226, saving model to weights-best-model.hdf5\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8652 - masked_rmse_loss: 0.9301 - val_loss: 0.9629 - val_masked_rmse_loss: 0.9824\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.98226 to 0.96295, saving model to weights-best-model.hdf5\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8528 - masked_rmse_loss: 0.9234 - val_loss: 0.9668 - val_masked_rmse_loss: 0.9842\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.96295\n",
      "Model: \"model_113\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Itemcontent (InputLayer)        [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "UserScore (InputLayer)          [(None, 6040)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_113 (Embedding)       (None, 2, 256)       25600       Itemcontent[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "EncLayer0 (Dense)               (None, 128)          773248      UserScore[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_113 (Flatten)           (None, 512)          0           embedding_113[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "UserLatentSpace (Dense)         (None, 256)          33024       EncLayer0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ItemLatentSpace (Dense)         (None, 256)          131328      flatten_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "LatentSpace (Add)               (None, 256)          0           UserLatentSpace[0][0]            \n",
      "                                                                 ItemLatentSpace[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 256)          0           LatentSpace[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "DecLayer0 (Dense)               (None, 512)          131584      dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "UserScorePred (Dense)           (None, 6040)         3098520     DecLayer0[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,193,304\n",
      "Trainable params: 4,193,304\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "autoenc_model = AutoEncContentModel(layers, epochs, batch, activation, dropout, lr, reg)\n",
    "\n",
    "# Input - We add content information for users\n",
    "X = [ratings_train, df_users[['occupation', 'age']].values]\n",
    "y = ratings_train\n",
    "\n",
    "# Train\n",
    "model, hist = autoenc_model.fit(X, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "fwMv947OoYU3",
    "outputId": "879280be-b10f-4ee1-f8f3-a090533afdb9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoenc_model.plot_loss_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQmxDVgO9zMw",
    "outputId": "6971ed7b-711a-4868-9be0-2733080ea4e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE on train: 0.9239262938499451\n",
      "Model RMSE on validation: 0.9829719662666321\n"
     ]
    }
   ],
   "source": [
    "print(\"Model RMSE on train:\", autoenc_model.history.history['masked_rmse_loss'][-1])\n",
    "print(\"Model RMSE on validation:\", autoenc_model.history.history['val_masked_rmse_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "_6tifdrZ-VV_",
    "outputId": "c7871060-890f-4c5e-c432-4ee24679c6f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3459, 6040) (3459, 2) (3459, 6040)\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.9232 - masked_rmse_loss: 0.9600\n",
      "Model RMSE on test set: 0.960034966468811\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = [ratings_test, df_users[['occupation', 'age']].values[:ratings_test.shape[0],:]]\n",
    "y_test = ratings_test\n",
    "print(X_test[0].shape, X_test[1].shape, y_test.shape)\n",
    "test_rmse = autoenc_model.model.evaluate(X_test, y_test)[1]\n",
    "print(\"Model RMSE on test set:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13AFJ-rJt3GV"
   },
   "source": [
    "##Hyperparameters Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wn9THf2Xt8Ii",
    "outputId": "15cbf9ed-a89d-498a-fe37-02035e321aae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 108 models for Hyper-parameter tuning...\n",
      "Model 1\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.19871, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.19871 to 1.17916, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.17916\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.17916\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.17916 to 1.12350, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.12350 to 1.08493, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.08493 to 1.07186, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.07186 to 1.01953, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.01953 to 0.98734, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.98734 to 0.97960, saving model to weights-best-model.hdf5\n",
      "Model 2\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.35772, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.35772 to 1.29514, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.29514 to 1.08329, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.08329 to 1.01627, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01627\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01627 to 1.00590, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00590 to 0.99967, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.99967 to 0.98297, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.98297\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.98297\n",
      "Model 3\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.75026, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.75026 to 2.13037, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.13037\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.13037\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.13037\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.13037\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.13037\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.13037\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.13037\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.13037\n",
      "Model 4\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.29506, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.29506 to 1.23071, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.23071 to 1.19586, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.19586 to 1.13421, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.13421 to 1.07192, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.07192 to 1.05572, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.05572 to 1.00529, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00529 to 0.97040, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.97040 to 0.96141, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.96141\n",
      "Model 5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.53461, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.53461 to 1.44429, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.44429 to 1.16782, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.16782 to 1.06429, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.06429 to 1.02650, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.02650 to 1.01362, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01362 to 0.98521, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.98521 to 0.97922, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.97922\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.97922 to 0.97891, saving model to weights-best-model.hdf5\n",
      "Model 6\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 18.49861, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 18.49861 to 7.96109, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 7.96109 to 5.22237, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.22237 to 4.39467, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.39467 to 4.25409, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.25409\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.25409\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.25409\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.25409\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.25409\n",
      "Model 7\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.39323, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.39323 to 1.29641, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.29641 to 1.22377, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.22377 to 1.09102, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.09102 to 1.00311, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00311 to 0.97603, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.97603 to 0.97016, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.97016 to 0.95834, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.95834\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.95834 to 0.95289, saving model to weights-best-model.hdf5\n",
      "Model 8\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59683, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.59683 to 1.44859, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.44859 to 1.35032, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.35032 to 1.16672, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.16672 to 1.14087, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.14087 to 1.08207, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.08207 to 1.07753, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.07753 to 1.04605, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.04605\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.04605 to 1.03774, saving model to weights-best-model.hdf5\n",
      "Model 9\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 115.82242, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 115.82242 to 36.82395, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 36.82395 to 16.00027, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 16.00027 to 11.51570, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 11.51570\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 11.51570\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 11.51570\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 11.51570\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 11.51570\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 11.51570\n",
      "Model 10\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.20011, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.20011 to 1.18822, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.18822\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.18822 to 1.18280, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.18280 to 1.16491, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.16491 to 1.11676, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.11676 to 1.09161, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.09161 to 1.03904, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.03904 to 1.01162, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.01162 to 1.00755, saving model to weights-best-model.hdf5\n",
      "Model 11\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.38722, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.38722 to 1.30464, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.30464 to 1.07772, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.07772 to 1.02572, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.02572 to 1.00160, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00160 to 0.99937, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.99937 to 0.99651, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.99651\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.99651\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.99651 to 0.96573, saving model to weights-best-model.hdf5\n",
      "Model 12\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.80962, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.80962 to 3.33838, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.33838 to 2.73176, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.73176\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.73176\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.73176\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.73176\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.73176\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.73176\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.73176\n",
      "Model 13\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.31831, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.31831 to 1.25194, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25194 to 1.20720, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.20720 to 1.13643, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.13643 to 1.09268, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.09268 to 1.03363, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.03363 to 1.01528, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.01528 to 0.98286, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.98286 to 0.96758, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.96758\n",
      "Model 14\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60434, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60434 to 1.31849, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.31849 to 1.05541, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.05541 to 1.03643, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.03643 to 0.99793, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.99793 to 0.99619, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.99619 to 0.98594, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.98594\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.98594 to 0.97807, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.97807\n",
      "Model 15\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 24.21120, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 24.21120 to 9.21489, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 9.21489 to 6.95895, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.95895 to 4.66946, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.66946\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.66946\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.66946\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.66946\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.66946\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.66946\n",
      "Model 16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.36880, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.36880 to 1.25703, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25703 to 1.20654, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.20654 to 1.07630, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.07630 to 1.00073, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00073 to 0.97038, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.97038\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.97038 to 0.96516, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.96516\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.96516 to 0.94854, saving model to weights-best-model.hdf5\n",
      "Model 17\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.57924, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.57924 to 1.46624, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.46624 to 1.30512, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.30512 to 1.14671, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.14671 to 1.14225, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.14225 to 1.08906, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.08906 to 1.06149, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.06149 to 1.04087, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.04087\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.04087\n",
      "Model 18\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 107.78352, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 107.78352 to 44.31812, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 44.31812 to 25.53832, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 25.53832 to 9.19058, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 9.19058\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 9.19058\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 9.19058\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 9.19058\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 9.19058\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 9.19058\n",
      "Model 19\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.21491, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.21491 to 1.17843, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.17843\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.17843 to 1.17612, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.17612 to 1.12264, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.12264 to 1.07674, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.07674 to 1.05493, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.05493 to 1.02509, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.02509 to 1.00525, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00525 to 0.98822, saving model to weights-best-model.hdf5\n",
      "Model 20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.34315, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.34315 to 1.32262, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.32262 to 1.06095, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.06095\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.06095 to 1.00626, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00626\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00626 to 0.99385, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.99385\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.99385 to 0.96474, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.96474\n",
      "Model 21\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.88781, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.88781 to 2.09835, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.09835 to 2.01127, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.01127\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.01127\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.01127\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.01127\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.01127\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.01127\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.01127\n",
      "Model 22\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.29942, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.29942 to 1.21440, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.21440 to 1.16120, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.16120 to 1.11693, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.11693 to 1.06687, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.06687 to 1.02370, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.02370 to 0.98181, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.98181 to 0.96941, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.96941 to 0.96742, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.96742 to 0.95566, saving model to weights-best-model.hdf5\n",
      "Model 23\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.54326, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.54326 to 1.27701, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.27701 to 1.10068, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.10068 to 1.04051, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.04051\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.04051 to 0.97864, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.97864\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.97864 to 0.97484, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.97484\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.97484 to 0.96780, saving model to weights-best-model.hdf5\n",
      "Model 24\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 25.76211, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 25.76211 to 9.47032, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 9.47032 to 6.84904, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.84904 to 6.22000, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.22000 to 5.30984, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 5.30984\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 5.30984\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 5.30984\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 5.30984\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 5.30984\n",
      "Model 25\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.41617, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.41617 to 1.28584, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.28584 to 1.16746, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.16746 to 1.05092, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.05092 to 1.03228, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.03228 to 0.97258, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.97258 to 0.97068, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.97068 to 0.96791, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.96791 to 0.95590, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.95590 to 0.95499, saving model to weights-best-model.hdf5\n",
      "Model 26\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.49631, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.49631 to 1.39994, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.39994\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.39994 to 1.36385, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.36385 to 1.24994, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.24994 to 1.17384, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.17384 to 1.16330, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.16330 to 1.11181, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.11181\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.11181 to 1.10414, saving model to weights-best-model.hdf5\n",
      "Model 27\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 101.10999, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 101.10999 to 32.81140, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 32.81140 to 18.19802, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 18.19802 to 10.91747, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 10.91747 to 9.88799, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 9.88799\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 9.88799\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 9.88799\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 9.88799\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 9.88799\n",
      "Model 28\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.12865, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.12865 to 1.17963, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.17963\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.17963\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.17963 to 1.11723, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.11723 to 1.07835, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.07835 to 1.06901, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.06901 to 1.02158, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.02158 to 1.00275, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00275 to 0.99693, saving model to weights-best-model.hdf5\n",
      "Model 29\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.36069, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.36069 to 1.30206, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.30206 to 1.16383, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.16383 to 1.02737, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.02737 to 1.00073, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00073\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00073 to 0.98107, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.98107\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.98107\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.98107\n",
      "Model 30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.96365, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.96365 to 2.35288, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.35288\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.35288 to 2.28805, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.28805 to 2.27042, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.27042\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.27042\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.27042\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.27042\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.27042\n",
      "Model 31\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.32443, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.32443 to 1.25139, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25139 to 1.19511, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.19511 to 1.16006, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.16006 to 1.07996, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.07996 to 1.03709, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.03709 to 1.01583, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.01583 to 0.98895, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.98895 to 0.97437, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.97437 to 0.96451, saving model to weights-best-model.hdf5\n",
      "Model 32\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.68840, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.68840 to 1.44342, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.44342 to 1.17694, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.17694 to 1.08287, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.08287 to 1.02311, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.02311 to 0.99917, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.99917 to 0.99842, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.99842 to 0.98351, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.98351\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.98351 to 0.98150, saving model to weights-best-model.hdf5\n",
      "Model 33\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 26.28311, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 26.28311 to 8.74781, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 8.74781 to 6.51171, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 6.51171\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.51171 to 5.82648, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.82648 to 5.54847, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 5.54847\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 5.54847\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 5.54847\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 5.54847\n",
      "Model 34\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.42801, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.42801 to 1.31254, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.31254 to 1.17810, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.17810 to 1.06669, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.06669 to 1.00064, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00064 to 0.97465, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.97465 to 0.96674, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.96674 to 0.96139, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.96139 to 0.95602, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.95602 to 0.95495, saving model to weights-best-model.hdf5\n",
      "Model 35\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.47990, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.47990 to 1.21570, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.21570 to 1.08535, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.08535 to 1.07181, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.07181 to 1.06479, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.06479\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.06479 to 1.04362, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.04362 to 1.01639, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.01639\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.01639 to 1.01073, saving model to weights-best-model.hdf5\n",
      "Model 36\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 118.83367, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 118.83367 to 45.23996, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 45.23996 to 21.74781, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 21.74781 to 21.07144, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 21.07144 to 19.57643, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 19.57643 to 17.63256, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 17.63256 to 16.31671, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 16.31671\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 16.31671\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 16.31671\n",
      "Model 37\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.25208, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.25208\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.25208 to 1.31901, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.31901 to 1.17357, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.17357\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.17357\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.17357\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.17357 to 1.17130, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.17130 to 1.13633, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.13633 to 1.10615, saving model to weights-best-model.hdf5\n",
      "Model 38\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.31136, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.31136 to 1.29319, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.29319 to 1.23074, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23074\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23074\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.23074 to 1.15096, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.15096 to 1.08319, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.08319 to 0.99917, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.99917 to 0.99366, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.99366 to 0.98934, saving model to weights-best-model.hdf5\n",
      "Model 39\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.15548, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.15548 to 2.96226, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.96226 to 2.17070, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.17070 to 2.13097, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.13097 to 1.83673, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.83673\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.83673\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.83673\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.83673\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.83673\n",
      "Model 40\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.22741, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.22741 to 1.28258, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.28258\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.28258 to 1.20122, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.20122\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.20122 to 1.16374, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.16374 to 1.13054, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.13054 to 1.09046, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.09046 to 1.07465, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.07465 to 1.04959, saving model to weights-best-model.hdf5\n",
      "Model 41\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.18345, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.18345 to 1.52356, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.52356 to 1.38102, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.38102 to 1.35101, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.35101 to 1.34117, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.34117 to 1.31882, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.31882 to 1.27113, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.27113 to 1.06378, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.06378 to 1.02977, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.02977 to 1.02500, saving model to weights-best-model.hdf5\n",
      "Model 42\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 23.49458, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 23.49458 to 13.14529, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 13.14529 to 7.16293, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 7.16293 to 4.55075, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.55075 to 3.19517, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.19517 to 3.08779, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.08779 to 2.46845, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.46845 to 2.40974, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.40974\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.40974\n",
      "Model 43\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.53291, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.53291 to 1.37625, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.37625 to 1.17021, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.17021\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.17021 to 1.16181, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.16181 to 1.14641, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.14641 to 1.11810, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.11810 to 1.04345, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.04345 to 0.98766, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.98766 to 0.96205, saving model to weights-best-model.hdf5\n",
      "Model 44\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60875, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60875 to 1.51078, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.51078 to 1.40381, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.40381 to 1.37040, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.37040\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.37040 to 1.33922, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.33922 to 1.16828, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.16828 to 1.10663, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.10663\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.10663 to 1.06094, saving model to weights-best-model.hdf5\n",
      "Model 45\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 123.40303, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 123.40303 to 73.78294, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 73.78294 to 29.22693, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 29.22693 to 15.62404, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 15.62404 to 11.47054, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 11.47054 to 7.57065, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 7.57065 to 7.38401, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 7.38401\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 7.38401\n",
      "\n",
      "Epoch 00010: val_loss improved from 7.38401 to 6.39373, saving model to weights-best-model.hdf5\n",
      "Model 46\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.17908, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.17908\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.17908 to 1.32953, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.32953 to 1.17890, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.17890\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.17890\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.17890\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.17890\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.17890 to 1.16578, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.16578 to 1.12257, saving model to weights-best-model.hdf5\n",
      "Model 47\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.32207, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.32207 to 1.26902, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.26902 to 1.20376, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.20376 to 1.18406, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.18406 to 1.09129, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.09129 to 1.02082, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.02082 to 0.99577, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.99577\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.99577\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.99577\n",
      "Model 48\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.03433, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.03433 to 3.14125, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.14125 to 2.24718, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.24718 to 2.01723, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.01723 to 1.77608, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.77608 to 1.72663, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.72663 to 1.72062, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.72062\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.72062\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.72062\n",
      "Model 49\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.16087, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.16087 to 1.27589, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.27589\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.27589 to 1.20335, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.20335\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.20335 to 1.16160, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.16160 to 1.15359, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.15359 to 1.11448, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.11448 to 1.07364, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.07364 to 1.04980, saving model to weights-best-model.hdf5\n",
      "Model 50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.96336, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.96336 to 1.46510, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.46510 to 1.36011, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.36011 to 1.31784, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.31784 to 1.30992, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.30992 to 1.27543, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.27543 to 1.11423, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.11423 to 1.02172, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.02172\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.02172 to 0.99178, saving model to weights-best-model.hdf5\n",
      "Model 51\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 25.33825, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 25.33825 to 14.05340, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 14.05340 to 7.08585, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 7.08585 to 5.04269, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.04269 to 3.23347, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.23347\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.23347 to 2.88694, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.88694 to 2.66743, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.66743\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.66743\n",
      "Model 52\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.53350, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.53350 to 1.34868, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.34868 to 1.16884, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.16884\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.16884 to 1.15671, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.15671 to 1.14182, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.14182 to 1.11716, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.11716 to 1.07095, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.07095 to 1.00670, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00670 to 0.96449, saving model to weights-best-model.hdf5\n",
      "Model 53\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.49786, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.49786 to 1.34592, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.34592 to 1.21817, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.21817 to 1.11461, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.11461 to 1.05032, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.05032\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.05032 to 1.01307, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01307\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.01307\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.01307 to 0.99852, saving model to weights-best-model.hdf5\n",
      "Model 54\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 150.62956, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 150.62956 to 84.32618, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 84.32618 to 36.50702, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 36.50702 to 16.55207, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 16.55207 to 9.59884, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 9.59884 to 6.83439, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.83439 to 5.17193, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 5.17193\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 5.17193\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 5.17193\n",
      "Model 55\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.20220, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.20220\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.20220 to 1.33486, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.33486 to 1.17464, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.17464\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.17464\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.17464\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.17464\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.17464 to 1.16938, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.16938 to 1.13449, saving model to weights-best-model.hdf5\n",
      "Model 56\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.29023, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.29023 to 1.25586, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25586 to 1.23494, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23494\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.23494 to 1.18560, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.18560 to 1.04680, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.04680 to 1.02245, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.02245 to 0.97346, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.97346\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.97346\n",
      "Model 57\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.36413, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.36413 to 4.11428, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.11428 to 2.59820, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.59820 to 2.18829, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.18829 to 1.88967, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.88967 to 1.79337, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.79337\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.79337\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.79337 to 1.78505, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.78505\n",
      "Model 58\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.16450, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.16450 to 1.27275, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.27275\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.27275 to 1.20067, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.20067\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.20067 to 1.17450, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.17450 to 1.14421, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.14421 to 1.12008, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.12008 to 1.09025, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.09025 to 1.05622, saving model to weights-best-model.hdf5\n",
      "Model 59\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.21135, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.21135 to 1.52908, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.52908 to 1.42642, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.42642\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.42642 to 1.35013, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.35013 to 1.28217, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.28217 to 1.18218, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.18218 to 1.06707, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.06707 to 1.00939, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00939 to 0.99778, saving model to weights-best-model.hdf5\n",
      "Model 60\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 33.97797, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 33.97797 to 17.24357, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 17.24357 to 8.33981, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 8.33981 to 4.28338, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.28338 to 2.74809, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.74809\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.74809\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.74809\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.74809\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.74809\n",
      "Model 61\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.52123, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.52123 to 1.38689, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.38689 to 1.16998, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.16998\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.16998 to 1.15824, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.15824 to 1.14748, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.14748 to 1.09212, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.09212 to 1.03798, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.03798 to 0.98679, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.98679 to 0.96293, saving model to weights-best-model.hdf5\n",
      "Model 62\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.42813, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.42813 to 1.35118, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.35118 to 1.27826, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.27826 to 1.11054, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.11054 to 1.06394, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.06394 to 1.05432, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.05432 to 1.01885, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.01885 to 1.00479, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00479\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00479\n",
      "Model 63\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 139.80119, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 139.80119 to 82.83266, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 82.83266 to 34.52244, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 34.52244 to 20.94768, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 20.94768 to 13.04467, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 13.04467 to 10.75316, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 10.75316\n",
      "\n",
      "Epoch 00008: val_loss improved from 10.75316 to 9.48059, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 9.48059 to 4.82218, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.82218\n",
      "Model 64\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.42557, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.42557 to 2.30452, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.30452 to 1.31984, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.31984 to 1.16962, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.16962\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.16962\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.16962\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.16962 to 1.15237, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.15237 to 1.11923, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.11923 to 1.09873, saving model to weights-best-model.hdf5\n",
      "Model 65\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.31060, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.31060 to 1.25182, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25182 to 1.21397, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.21397\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.21397 to 1.16810, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.16810 to 1.06445, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.06445 to 1.05107, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.05107 to 1.00594, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00594\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00594 to 0.98002, saving model to weights-best-model.hdf5\n",
      "Model 66\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.20411, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.20411 to 2.69790, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.69790 to 1.87291, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.87291 to 1.82865, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.82865 to 1.65065, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.65065\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.65065\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.65065\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.65065\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.65065\n",
      "Model 67\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.12818, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.12818 to 1.27652, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.27652\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.27652 to 1.20225, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.20225\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.20225 to 1.16368, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.16368 to 1.14027, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.14027 to 1.10862, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.10862 to 1.07098, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.07098 to 1.04347, saving model to weights-best-model.hdf5\n",
      "Model 68\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.17589, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.17589 to 1.57262, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.57262 to 1.37776, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.37776 to 1.34170, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.34170\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.34170 to 1.26145, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.26145 to 1.13966, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.13966 to 1.04051, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.04051 to 1.01843, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.01843 to 0.99231, saving model to weights-best-model.hdf5\n",
      "Model 69\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 32.90583, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 32.90583 to 17.71059, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 17.71059 to 7.84825, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 7.84825 to 4.54819, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.54819 to 3.29465, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.29465 to 2.94187, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.94187 to 2.62167, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.62167\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.62167\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.62167\n",
      "Model 70\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.52660, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.52660 to 1.36071, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.36071 to 1.17204, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.17204\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.17204 to 1.16325, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.16325 to 1.15249, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.15249 to 1.10809, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.10809 to 1.05037, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.05037 to 0.99131, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.99131 to 0.97434, saving model to weights-best-model.hdf5\n",
      "Model 71\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.55806, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.55806 to 1.38071, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.38071 to 1.35228, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.35228 to 1.20421, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.20421 to 1.08930, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.08930 to 1.05936, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.05936 to 1.05745, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.05745 to 1.05434, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.05434 to 1.03384, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.03384 to 1.02030, saving model to weights-best-model.hdf5\n",
      "Model 72\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 130.09363, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 130.09363 to 67.73546, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 67.73546 to 29.24078, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 29.24078 to 14.23637, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 14.23637 to 9.45859, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 9.45859 to 6.03304, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.03304 to 5.15256, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 5.15256 to 3.68393, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.68393\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.68393\n",
      "Model 73\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.55744, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.55744 to 1.76322, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.76322\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.76322\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.76322 to 1.56145, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.56145 to 1.20989, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.20989 to 1.15341, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.15341\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.15341\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.15341\n",
      "Model 74\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.42049, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.42049 to 1.31789, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.31789 to 1.28887, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.28887 to 1.17519, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.17519\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.17519 to 1.15305, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.15305\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.15305\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.15305\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.15305\n",
      "Model 75\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.26468, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.26468 to 5.22265, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.22265 to 2.95870, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.95870 to 2.34001, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.34001 to 1.88830, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.88830 to 1.80811, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.80811 to 1.61848, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.61848 to 1.61164, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.61164 to 1.57610, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.57610 to 1.51407, saving model to weights-best-model.hdf5\n",
      "Model 76\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.05848, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.05848\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.05848 to 1.62202, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.62202 to 1.27129, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.27129 to 1.15681, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.15681\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.15681\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.15681 to 1.15316, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.15316\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.15316\n",
      "Model 77\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.01400, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.01400 to 1.70266, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.70266 to 1.24649, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24649\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24649\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.24649 to 1.22477, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.22477\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.22477\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.22477\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.22477\n",
      "Model 78\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 24.60333, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 24.60333\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 24.60333\n",
      "\n",
      "Epoch 00004: val_loss improved from 24.60333 to 13.32383, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 13.32383 to 8.11755, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 8.11755 to 5.27345, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 5.27345 to 3.87084, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.87084 to 3.20126, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.20126 to 3.03323, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.03323 to 2.30689, saving model to weights-best-model.hdf5\n",
      "Model 79\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.16091, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.16091 to 1.32089, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.32089 to 1.28950, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.28950\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.28950 to 1.19225, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.19225 to 1.13927, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.13927\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.13927\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.13927\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.13927\n",
      "Model 80\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.68480, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.68480 to 1.41381, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.41381 to 1.32194, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.32194 to 1.27370, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.27370 to 1.26841, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.26841\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.26841\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.26841 to 1.21213, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.21213 to 1.11343, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.11343 to 1.04688, saving model to weights-best-model.hdf5\n",
      "Model 81\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 79.31289, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 79.31289\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 79.31289\n",
      "\n",
      "Epoch 00004: val_loss improved from 79.31289 to 64.52029, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 64.52029 to 28.07773, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 28.07773 to 18.02350, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 18.02350 to 13.31012, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 13.31012 to 8.67523, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 8.67523 to 5.87473, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 5.87473 to 4.24997, saving model to weights-best-model.hdf5\n",
      "Model 82\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.57553, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.57553 to 1.78058, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.78058\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.78058\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.78058 to 1.54198, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.54198 to 1.20620, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.20620 to 1.15329, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.15329\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.15329\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.15329\n",
      "Model 83\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.34668, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.34668 to 1.27978, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.27978\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.27978 to 1.16854, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.16854\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.16854 to 1.15138, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.15138\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.15138\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.15138\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.15138\n",
      "Model 84\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.17504, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.17504 to 5.95487, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.95487 to 3.60235, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.60235 to 2.46614, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.46614 to 1.95212, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.95212 to 1.77156, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.77156 to 1.75036, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.75036 to 1.56967, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.56967\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.56967 to 1.49391, saving model to weights-best-model.hdf5\n",
      "Model 85\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.01419, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.01419\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.01419 to 1.63938, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.63938 to 1.28309, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.28309 to 1.16022, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.16022\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.16022\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.16022 to 1.15245, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.15245\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.15245\n",
      "Model 86\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.97376, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.97376 to 1.76087, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.76087 to 1.24341, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24341\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.24341 to 1.23060, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.23060 to 1.22417, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.22417\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.22417\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.22417\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.22417\n",
      "Model 87\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 18.10556, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 18.10556\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 18.10556\n",
      "\n",
      "Epoch 00004: val_loss improved from 18.10556 to 8.59715, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 8.59715 to 5.78456, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.78456 to 4.82989, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.82989 to 2.96058, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.96058 to 2.54083, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.54083 to 2.08995, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.08995 to 1.97027, saving model to weights-best-model.hdf5\n",
      "Model 88\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.10835, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.10835 to 1.31028, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.31028 to 1.28787, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.28787\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.28787 to 1.20915, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.20915 to 1.14535, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.14535\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.14535\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.14535 to 1.14040, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.14040\n",
      "Model 89\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.85987, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.85987 to 1.47196, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.47196 to 1.35427, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.35427 to 1.34875, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.34875\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.34875 to 1.31350, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.31350 to 1.31287, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.31287 to 1.29630, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.29630\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.29630\n",
      "Model 90\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 88.09834, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 88.09834\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 88.09834\n",
      "\n",
      "Epoch 00004: val_loss improved from 88.09834 to 62.82859, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 62.82859 to 28.40384, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 28.40384 to 19.03115, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 19.03115 to 12.64648, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 12.64648 to 7.53064, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 7.53064 to 6.88700, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 6.88700 to 4.66667, saving model to weights-best-model.hdf5\n",
      "Model 91\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.52981, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.52981 to 1.75794, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.75794\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.75794\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.75794 to 1.53920, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.53920 to 1.21015, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.21015 to 1.15733, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.15733\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.15733\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.15733\n",
      "Model 92\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.33650, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.33650 to 1.28695, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.28695 to 1.26707, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.26707 to 1.16452, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.16452\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.16452 to 1.15084, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.15084\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.15084 to 1.13631, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.13631 to 1.09629, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.09629 to 1.00889, saving model to weights-best-model.hdf5\n",
      "Model 93\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.96041, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.96041 to 5.76776, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.76776 to 3.30834, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.30834 to 2.39653, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.39653 to 1.95784, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.95784 to 1.72417, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.72417 to 1.66156, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.66156 to 1.56549, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.56549 to 1.50562, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.50562 to 1.49510, saving model to weights-best-model.hdf5\n",
      "Model 94\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.97682, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.97682\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.97682 to 1.63701, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.63701 to 1.26964, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.26964 to 1.15628, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.15628\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.15628\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.15628 to 1.15295, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.15295\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.15295\n",
      "Model 95\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.88293, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.88293 to 1.70275, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.70275 to 1.25350, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.25350\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.25350 to 1.20732, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.20732\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.20732\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.20732\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.20732\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.20732\n",
      "Model 96\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 21.50925, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 21.50925\n",
      "\n",
      "Epoch 00003: val_loss improved from 21.50925 to 20.91874, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 20.91874 to 7.69050, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 7.69050 to 5.23239, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.23239 to 4.41582, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.41582 to 3.24951, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.24951 to 2.48776, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.48776 to 2.07543, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.07543 to 2.04197, saving model to weights-best-model.hdf5\n",
      "Model 97\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.14610, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.14610 to 1.33324, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.33324 to 1.29872, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.29872\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.29872 to 1.20894, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.20894 to 1.14491, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.14491\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.14491\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.14491 to 1.14017, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.14017\n",
      "Model 98\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.65773, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.65773 to 1.42297, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.42297 to 1.29421, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.29421\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.29421 to 1.28004, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.28004 to 1.26763, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.26763 to 1.24330, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.24330 to 1.23392, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.23392 to 1.14302, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.14302 to 1.05060, saving model to weights-best-model.hdf5\n",
      "Model 99\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 83.64788, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 83.64788\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 83.64788\n",
      "\n",
      "Epoch 00004: val_loss improved from 83.64788 to 60.54590, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 60.54590 to 27.12608, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 27.12608 to 16.76784, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 16.76784 to 11.30880, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 11.30880 to 7.99631, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 7.99631 to 6.25370, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 6.25370 to 5.08744, saving model to weights-best-model.hdf5\n",
      "Model 100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.58763, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.58763 to 1.78438, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.78438 to 1.77748, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.77748\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.77748 to 1.55785, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.55785 to 1.20943, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.20943 to 1.15464, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.15464\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.15464\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.15464\n",
      "Model 101\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.36432, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.36432 to 1.24561, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24561\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.24561 to 1.15834, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.15834\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.15834 to 1.14660, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.14660\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.14660 to 1.09043, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.09043 to 1.03215, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.03215 to 0.99772, saving model to weights-best-model.hdf5\n",
      "Model 102\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.82229, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.82229 to 4.51158, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.51158 to 3.16875, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.16875 to 2.07394, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.07394 to 1.70602, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.70602 to 1.63800, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.63800 to 1.55712, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.55712 to 1.42501, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.42501\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.42501\n",
      "Model 103\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.04536, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.04536\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.04536 to 1.64456, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.64456 to 1.27194, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.27194 to 1.15720, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.15720\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.15720\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.15720 to 1.15124, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.15124\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.15124\n",
      "Model 104\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.12606, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.12606 to 1.81748, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.81748 to 1.27642, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.27642\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.27642 to 1.23733, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23733\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23733\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23733\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23733\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.23733 to 1.23553, saving model to weights-best-model.hdf5\n",
      "Model 105\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 24.92555, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 24.92555\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 24.92555\n",
      "\n",
      "Epoch 00004: val_loss improved from 24.92555 to 11.47622, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 11.47622 to 6.65209, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.65209 to 5.65064, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 5.65064 to 3.54019, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.54019 to 2.73506, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.73506 to 2.46374, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.46374 to 2.15791, saving model to weights-best-model.hdf5\n",
      "Model 106\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.19155, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.19155 to 1.32501, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.32501 to 1.30770, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.30770\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.30770 to 1.21936, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.21936 to 1.14367, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.14367\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.14367\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.14367\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.14367\n",
      "Model 107\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.63106, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.63106 to 1.40650, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.40650 to 1.31353, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.31353 to 1.29333, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.29333 to 1.25487, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.25487\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.25487\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.25487 to 1.17837, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.17837 to 1.13303, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.13303 to 1.07419, saving model to weights-best-model.hdf5\n",
      "Model 108\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 87.76542, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 87.76542\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 87.76542\n",
      "\n",
      "Epoch 00004: val_loss improved from 87.76542 to 56.34672, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 56.34672 to 27.56201, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 27.56201 to 19.30731, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 19.30731 to 10.41189, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 10.41189 to 7.30868, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 7.30868 to 5.15844, saving model to weights-best-model.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 5.15844 to 4.49133, saving model to weights-best-model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Regularization</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Validation RMSE</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[64, 128, 256]</td>\n",
       "      <td>0.990823</td>\n",
       "      <td>1.769862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[64, 128, 256]</td>\n",
       "      <td>0.999747</td>\n",
       "      <td>1.738330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[64, 128, 256]</td>\n",
       "      <td>1.521975</td>\n",
       "      <td>1.537418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 256, 512]</td>\n",
       "      <td>0.987477</td>\n",
       "      <td>3.015024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 256, 512]</td>\n",
       "      <td>0.990616</td>\n",
       "      <td>2.973467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>10</td>\n",
       "      <td>512</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[128, 256, 512]</td>\n",
       "      <td>1.111544</td>\n",
       "      <td>8.065549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>10</td>\n",
       "      <td>512</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[128, 256, 512]</td>\n",
       "      <td>1.468983</td>\n",
       "      <td>13.188758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>10</td>\n",
       "      <td>512</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[256, 512, 1024]</td>\n",
       "      <td>1.084162</td>\n",
       "      <td>14.988685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>10</td>\n",
       "      <td>512</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[256, 512, 1024]</td>\n",
       "      <td>1.036431</td>\n",
       "      <td>25.841938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>10</td>\n",
       "      <td>512</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[256, 512, 1024]</td>\n",
       "      <td>2.119277</td>\n",
       "      <td>25.115993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epochs Batch size  Learning Rate  Regularization            Layers  \\\n",
       "0       10        128          0.001           0.001    [64, 128, 256]   \n",
       "1       10        128          0.010           0.001    [64, 128, 256]   \n",
       "2       10        128          0.100           0.001    [64, 128, 256]   \n",
       "3       10        128          0.001           0.001   [128, 256, 512]   \n",
       "4       10        128          0.010           0.001   [128, 256, 512]   \n",
       "..     ...        ...            ...             ...               ...   \n",
       "103     10        512          0.010           1.000   [128, 256, 512]   \n",
       "104     10        512          0.100           1.000   [128, 256, 512]   \n",
       "105     10        512          0.001           1.000  [256, 512, 1024]   \n",
       "106     10        512          0.010           1.000  [256, 512, 1024]   \n",
       "107     10        512          0.100           1.000  [256, 512, 1024]   \n",
       "\n",
       "     Validation RMSE       Time  \n",
       "0           0.990823   1.769862  \n",
       "1           0.999747   1.738330  \n",
       "2           1.521975   1.537418  \n",
       "3           0.987477   3.015024  \n",
       "4           0.990616   2.973467  \n",
       "..               ...        ...  \n",
       "103         1.111544   8.065549  \n",
       "104         1.468983  13.188758  \n",
       "105         1.084162  14.988685  \n",
       "106         1.036431  25.841938  \n",
       "107         2.119277  25.115993  \n",
       "\n",
       "[108 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "batch_sizes = [ 128, 256, 512 ]\n",
    "regularizations = [0.001, 0.01, 0.1, 1]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "layers_structures = [[64, 128, 256], [128, 256, 512], [256, 512, 1024]]\n",
    "\n",
    "epochs = 10 # Only one value due to computational power\n",
    "dropout = 0.6\n",
    "activation = 'sigmoid'\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['Epochs', 'Batch size', 'Learning Rate', 'Regularization', 'Layers', 'Validation RMSE', 'Time'])\n",
    "\n",
    "val_errors = {}\n",
    "train_errors = {}\n",
    "\n",
    "model_i = 1\n",
    "\n",
    "print(f\"Training {len(learning_rates) * len(batch_sizes) * len(regularizations) * len(layers_structures)} models for Hyper-parameter tuning...\")\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    for reg in regularizations:\n",
    "      for layers in layers_structures:\n",
    "        for lr in learning_rates:\n",
    "          print(f\"Model {model_i}\")\n",
    "          dic = {'Epochs':epochs, 'Batch size': bs, 'Regularization':reg, 'Layers':layers, 'Learning Rate': lr}\n",
    "          \n",
    "          start = time.time() \n",
    "          # Build model\n",
    "          model = AutoEncContentModel(layers, epochs, bs, activation, dropout, lr, reg)\n",
    "          # ---------------------------------------------\n",
    "          # Input\n",
    "          X = [ratings_train, df_users[['occupation', 'age']].values]\n",
    "          y = ratings_train\n",
    "\n",
    "          # Train\n",
    "          model, hist = model.fit(X, y, verbose=0)\n",
    "          \n",
    "          dic['Time'] = time.time() - start\n",
    "          dic['Validation RMSE'] = model.history.history['val_masked_rmse_loss'][-1]\n",
    "\n",
    "          results = results.append(dic, ignore_index=True)\n",
    "          model_i += 1 \n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "rGPGojWj0NYZ",
    "outputId": "4f5ab7fd-7d74-497e-caa5-77816f4158d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Regularization</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Validation RMSE</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>[256, 512, 1024]</td>\n",
       "      <td>0.975064</td>\n",
       "      <td>4.603702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[256, 512, 1024]</td>\n",
       "      <td>0.977279</td>\n",
       "      <td>6.263547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.100</td>\n",
       "      <td>[256, 512, 1024]</td>\n",
       "      <td>0.978316</td>\n",
       "      <td>5.211881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epochs Batch size  Learning Rate  Regularization            Layers  \\\n",
       "15     10        128          0.001           0.010  [256, 512, 1024]   \n",
       "6      10        128          0.001           0.001  [256, 512, 1024]   \n",
       "24     10        128          0.001           0.100  [256, 512, 1024]   \n",
       "\n",
       "    Validation RMSE      Time  \n",
       "15         0.975064  4.603702  \n",
       "6          0.977279  6.263547  \n",
       "24         0.978316  5.211881  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results['Validation RMSE'].nsmallest(3).index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epochs                           10\n",
       "Batch size                      128\n",
       "Learning Rate                 0.001\n",
       "Regularization                 0.01\n",
       "Layers             [256, 512, 1024]\n",
       "Validation RMSE            0.975064\n",
       "Time                       4.603702\n",
       "Name: 15, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = results.loc[15]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "98AhMwWjURh5"
   },
   "outputs": [],
   "source": [
    "def understanding_the_effect(hyper_param):\n",
    "  y = 'Validation RMSE'\n",
    "  plt.plot(results.groupby(hyper_param)[y].mean())\n",
    "  plt.xlabel(hyper_param)\n",
    "  plt.ylabel(y)\n",
    "  plt.title(hyper_param)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZxkdXnv8c+3u2fr2Xqme5BZehYWlUWmgR6vmCiL5gZxT1BBjY4xcpWE5MbINYlRMDG5EjUXDQoZE14jegUD6Ig7iiBRQR1ghkU2wdlYZobZGGalq578cU7NnO6prq6erqW76vt+vfrVVXVOnfPULP307/f8FkUEZmZmA7XUOwAzMxudnCDMzKwoJwgzMyvKCcLMzIpygjAzs6KcIMzMrCgnCLNhknSppK+M4P1XSfpoJWNKr/s9Se+u9HWtebXVOwCzkZC0BngBkAOeA74P/FlEPFfPuEqJiPeP9BqSLgWOiYh3Zq77mpFe1yzLLQhrBK+PiClAD3Ay8Dd1jmdQklrrHYNZuZwgrGFExNPAD0gSBZJeJunnkrZLWi3pjMK5khZJul3STkk/kvT5QreRpDMkbcheW9IaSa8udl9J10t6WtKO9JonZI4tl3SlpO9K2gWcmb72ifT4tyQ9l/nKS1qaHvuspPWSnpV0l6RXpK+fDfwt8Lb0PavT12+T9Cfp4xZJfydpraRNkq6RND09tlBSSHq3pHWSnpH0kQr8FViDcYKwhiFpHvAa4DeS5gLfAT4BzAQ+BNwoaVZ6+leBXwKdwKXAH43g1t8DjgWOAO4G/v+A428H/hGYCvw0eyAiXh8RU9IW0FuAp4Fb0sO/Ikl2M9N4r5c0MSK+D/wT8LX0vYuLxLQ0/ToTOAqYAlwx4JzfBV4EvAr4mKTjhvexrdE5QVgjWCFpJ7Ae2ARcArwT+G5EfDci8hHxQ2AlcI6k+cAS4GMRsT8ifgrcdLg3j4irI2JnROwjSTaLC7+tp74ZET9L49hb7BqSXgh8CXhrRKxPr/uViNgSEX0R8RlgAskP9HK8A/iXiHg8rcf8DXCepGzd8eMRsSciVgOrgWKJxpqYE4Q1gjdFxFTgDODFQBewAHhL2r20XdJ2kt+YZwNzgK0RsTtzjfWHc2NJrZI+KekxSc8Ca9JDXeVeO00m3wT+Lk1Whdc/JOnBtOtqOzB9wHVLmQOszTxfSzIo5QWZ157OPN5N0sowO8AJwhpGRPwEWA58muSH8pcjoiPzNTkiPgk8BcyU1J55e3fm8S7gwLG0sDyL4t4OvBF4NckP8IWFt2VDGyxmSS0k3Ue3RsSyzOuvAP4P8FZgRkR0ADsy1x1qGeYnSZJkwXygD9g4xPvMDnCCsEZzOfB7wM+B10v6/fS3/Ilp8XleRKwl6W66VNJ4SacBr89c4xFgoqTXShoH/B1J904xU4F9wBaSpPJPw4z3H4HJwF8UuW4fsBlok/QxYFrm+EZgYZpgirkW+Mu0GD+FgzWLvmHGZ03MCcIaSkRsBq4B/pzkN/u/Jfkhux64mIP/5t8BnEbyg/0TwNdIftATETuAC4F/B54gaVH0G9WUcQ1J980TwK+BO4cZ8vnAy4BtmZFM7yAZjfV9kmS1FthL/66q69PvWyTdXeS6VwNfBm4Hfpu+/6JhxmZNTt4wyAwkfQ14KCIuqXcsZqOFWxDWlCQtkXR0Ol/gbJLWxop6x2U2mnipDWtWRwJfJ5kHsQH4QETcU9+QzEYXdzGZmVlR7mIyM7OiGqaLqaurKxYuXFjvMMzMxpS77rrrmYgoOs+nYRLEwoULWblyZb3DMDMbUyStHeyYu5jMzKwoJwgzMyvKCcLMzIpygjAzs6KqliAkXZ3uZHX/EOctkdQn6dzMa/8s6YF0qePPSVKpa5iZWeVVswWxHDi71AnpMsqXATdnXns58DvAScCJJBu7nF61KM3MrKiqJYiIuB3YOsRpFwE3kuwCduCtwERgPMkSy+PwGvZmZjVXtxpEumfwm4Ers69HxB3ArSSbujwF/CAiHhzkGhdIWilp5ebNm0cc0+79fVy/cj1efsTMrL5F6suBD0dEPvuipGOA44B5wFzgrHR3rUNExLKI6I2I3lmzBtvwq3y3PrSZi2+4l5Vrt434WmZmY109Z1L3Atel9ecuks3k+4BjgTvTjdaR9D2SjV3+q9oB7c/lAFi1bjtLFs6s9u3MzEa1urUgImJRRCyMiIXADcCFEbECWAecLqkt3e7xdKBoF1Ol9eWSrqVVG7bX4nZmZqNa1VoQkq4FzgC6JG0ALiEpOBMRV5V46w3AWcB9JAXr70fEt6oVZ1Y+rT2sWucEYWZWtQQREecP49ylmcc54H9VI6ah9OWTBPHE9j1s3rmPWVMH26fezKzxeSZ1Rj5/cPTSqvVuRZhZc3OCyOjrlyA8ksnMmpsTREYuTRALOtvdgjCzpucEkVFIEKfOn8G963f063IyM2s2ThAZhS6mUxfOYOe+Ph7b/FydIzIzqx8niIxCi+HUBTMAuMfdTGbWxJwgMgotiGOPmMrUCW2uQ5hZU3OCyMhH0CJobREndU9ntROEmTUxJ4iMvnzQ1pL8kfR0d/DQ0zvZsz9X56jMzOrDCSIjnw/S/EBP9wxy+eD+J3fUNygzszpxgsgY2IIAr8tkZs3LCSIjl09qEACzpk5gbsckF6rNrGk5QWTk8kFb68E/kp75HU4QZta0nCAy+vJBa6EJAZzc3cET2/ewaefeOkZlZlYfThAZ+XzQqoMJwnUIM2tmThAZA1sQJ8yZTmuL3M1kZk3JCSIjH/0TxKTxrbz4yKlOEGbWlJwgMpJhrur3Wk93B/du8MquZtZ8nCAykolyhyaI57yyq5k1ISeIjL58/pAWxMnzk0K1V3Y1s2bjBJGRy0OL+ieIo7qmMHWiV3Y1s+bjBJGRy+dpa+2fIFpaxOJ5HR7qamZNxwkioy8fh7QgIKlDPLzRK7uaWXOpWoKQdLWkTZLuH+K8JZL6JJ2bPj9T0qrM115Jb6pWnFn5OHQUEyQJIpcP7nvCK7uaWfOoZgtiOXB2qRMktQKXATcXXouIWyOiJyJ6gLOA3dnj1dSX6z8PoqAnLVSvWr+tFmGYmY0KVUsQEXE7sHWI0y4CbgQ2DXL8XOB7EbG7krENZuBEuYKuKROYN8Mru5pZc6lbDULSXODNwJUlTjsPuLbENS6QtFLSys2bN484poFLbWQt7u5g9Xp3MZlZ86hnkfpy4MMRkS92UNJs4CXADwa7QEQsi4jeiOidNWvWiAPKl0gQXtnVzJpNPRNEL3CdpDUkXUlfGFCMfivwjYh4vlYBFVtqo8Aru5pZs6lbgoiIRRGxMCIWAjcAF0bEiswp51Oie6kacoMMcwU4ce502ryyq5k1kbZqXVjStcAZQJekDcAlwDiAiLhqiPcuBLqBn1QrvmKSHeWKJ4iJ41p58Wyv7GpmzaNqCSIizh/GuUsHPF8DzK1wSEMq1YKApJtpxT1PkitRqzAzaxSeSZ2RG2SiXEFP9wyv7GpmTcMJIiOZKDf4H4kL1WbWTJwgMpKJcoMfP6prMlMntnnpbzNrCk4QGclEucH/SFpaRE93hwvVZtYUnCAykolypc9ZPK+DRzbuZPf+vtoEZWZWJ04QGclEudJ/JIWVXe9/4tkaRWVmVh9OEBn5IYa5gld2NbPm4QSR0VdiolyBV3Y1s2bhBJEx1ES5gp5ub0FqZo3PCSJjqIlyBT3dHTy5Yy+bnvXKrmbWuJwgUhGRtCDKSBAnp3UIz4cws0bmBJHKR/K9nBbECXO8squZNT4niFRfPtm3qJxF+CaOa+W42dNchzCzhuYEkUrzQ9mrtPZ0d3Dvhu3kCk0PM7MG4wSRKrQgyuligiRB7Nqf88quZtawnCBShRZEOcNcARZ7ZVcza3BOEKkDLYghJsoVeGVXM2t0ThCpQi2h3BaEV3Y1s0bnBJHKRZIgyq1BQFKHePjpZ72yq5k1JCeIVF8ubUEMM0HkA+7bsKNaYZmZ1Y0TRCp/mC0IwN1MZtaQnCBSfWkNotx5EACdUybQPdMru5pZY3KCSOUPI0EA9HTPcIIws4Y0aIKQNK3EsflDXVjS1ZI2Sbp/iPOWSOqTdG72+pJulvSgpF9LWjjU/Uaq0IIYThcTJN1MT+3Yy0av7GpmDaZUC+K2wgNJtww4tqKMay8Hzi51gqRW4DLg5gGHrgE+FRHHAS8FNpVxvxEZ7jDXAtchzKxRlUoQ2Z+UM0scKyoibge2DnHaRcCNZBKApOOBtoj4YXqd5yJi91D3G6lCgih3olzBCXOmeWVXM2tIpRJEDPK42PNhkzQXeDNw5YBDLwS2S/q6pHskfSptaRS7xgWSVkpauXnz5hHF03eYLQiv7GpmjaqtxLEjJH2QpLVQeEz6fFYF7n058OGIyKv/D+U24BXAycA64GvAUuA/Bl4gIpYBywB6e3tHlLQODnMdft2+p7uDr9+9gVw+hl3kNjMbrUr9NPwiMBWYknlceP7vFbh3L3CdpDXAucAXJL0J2ACsiojHI6KPpN5xSgXuV9LBiXLDf29hZdffbPLKrmbWOAZtQUTEx6t544hYVHgsaTnw7YhYkXYndUiaFRGbgbOAldWMBUbYgphfKFRv40VHTq1oXGZm9VJqmOv7JB2bPlY6bHWHpHslnTzUhSVdC9wBvEjSBknvlfR+Se8v9b6IyAEfAm6RdB9Jl9YXh/OhDsfBiXLDf++izslMm9jmQrWZNZRSNYi/IBmqCnA+sBg4iqQ28DmSOsGgIuL8coOIiKUDnv8QOKnc91fCwYlyw88QLS1icXcH97hQbWYNpNRPw76IeD59/DrgmojYEhE/AiZXP7TaOtyJcgUnd3fwyMad7NrnlV3NrDGUShB5SbMlTQReBfwoc2xSdcOqvcOdKFfQMz9Z2fX+J7yyq5k1hlIJ4mMkxeE1wE0R8QCApNOBx6sfWm0d7kS5gsXzPKPazBpLqVFM35a0AJgaEdsyh1YCb6t6ZDVW2DDocFsQXtnVzBrNoAlC0h9kHhc75evVCKhecoU9qUcw0a2newYr1wy1uoiZ2dhQahTTDcCq9Av6r78UNFiCKEyUG8lM6J7uDr61+kk2PruXF0ybWKnQzMzqolSC+APgPJLhpt8Ero2I39QkqjooTJQbaYIAuGfdds4+8ciKxGVmVi+DFqkjYkVEnAecDjwGfEbST9MidcM5nB3lBjphzjTGtXplVzNrDOXMCtsL7ACeJVmHqSH7Tg53R7msAyu7rt829MlmZqNcqSL1WSRdTC8lmQPx2Yio+ppI9TLSiXIFPd0d3HiXV3Y1s7GvVAviRyTJ4afABOBdkj5X+KpJdDV0YKJcBRLErv05Ht20sxJhmZnVTaki9XtqFsUokKtgCwJg9frtvPjIQbf1NjMb9UpNlPvSYMckza9OOPUz0olyBYu6JjN90jhWrd/O25Y03B+TmTWRkkVqSadJOlfSEenzkyR9FfhZTaKroVyuMi0IySu7mlljKLUfxKeAq4E/BL4j6RPAzcAvgGNrE17tVGKYa0HPvOle2dXMxrxSNYjXAidHxF5JM4D1wIkRsaYmkdVYPoIWDbqsyLAUVna974kdvOyozgpEZ2ZWe6W6mPZGxF6AdLG+Rxs1OUDSgqjUsFSv7GpmjaBUC+IoSTdlni/KPo+IN1QvrNrLVzBBdE6ZwPyZ7axyHcLMxrBSCeKNA55/ppqB1FtfPmg7jO1GB9PT3cEvf+uVXc1s7Co1zPUntQyk3nL5pAZRKT3dHdy0+kme3rGXI6c35OokZtbgKvcr8xiXywdtrRVsQcwv1CG8LpOZjU1OEKlcxIgnyWUdP7uwsqv3qDazsalqCULS1ZI2Sbp/iPOWSOqTdG7mtZykVenXTaXeXym5XIx4klzWxHGtHO+VXc1sDCtVpAZA0guBi4EF2fMj4qwh3rocuAK4psS1W4HLSCbgZe2JiJ6hYqukSg5zLejp7uAGr+xqZmPUkAkCuB64CvgikCv3whFxu6SFQ5x2EXAjsKTc61ZLPir/Q3xxdwdfumMtj27a6YX7zGzMKSdB9EXElZW+saS5wJuBMzk0QUyUtBLoAz4ZESsqff+BqtWCAFi1ziu7mtnYU04N4luSLpQ0W9LMwlcF7n058OGIyBc5tiAieoG3A5dLOrrYBSRdIGmlpJWbN28eUTCVnChXkF3Z1cxsrCmnBfHu9PvFmdcCOGqE9+4FrkvXPuoCzpHUl+6F/QRARDwu6TbgZJJ9sfuJiGXAMoDe3t4YSTB9+TytFRzFBAdXdnWCMLOxaMgEERGLqnHj7HUlLQe+HREr0oUBd0fEPkldwO8A/1yNGLJy+cqs5DpQT3cHV/z4UXbt62PyhHLysZnZ6FDOKKZxwAeAV6Yv3Qb8W0Q8P8T7rgXOALokbQAuAcYBRMRVJd56HPBvkvIkXWCfjIhfDxXnSOXyedpaK58gTu5OVna9d8MOTjvaK7ua2dhRzq+0V5L8YP9C+vyP0tf+pNSbIuL8coOIiKWZxz8HXlLueyslFyPfTa6YxYUtSDdsd4IwszGlnASxJCIWZ57/WNLqagVUL7l8vqIT5QpmTh7Pgk6v7GpmY085o5hy2VFEko5iGPMhxoq+XNBSpclsPS5Um9kYVE6CuBi4VdJtkn4C/Bj4q+qGVXv5qOxSG1k93R08/exent6xtyrXNzOrhnJGMd0i6VjgRelLD0fEvuqGVXt9+WDiuOolCEhWdj17+uyq3MPMrNIGbUFIOiv9/gck+1Mfk369Nn2toVRjolzBcenKrve4m8nMxpBSLYjTSbqTXl/kWABfr0pEddKXj4pPlCs4sLKrC9VmNoaU2lHukvTh30fEb7PHJFVl8lw9VXvF1Z7uDq73yq5mNoaUU6S+schrN1Q6kHpLdpSrYoKY38Hu/Tke2bizavcwM6ukQVsQkl4MnABMH1BzmAY03CbLld5RbqCe7hkArFq/neNme2VXMxv9StUgXgS8Duigfx1iJ/C+agZVD7l89Ya5AizsbKejfRyr12/n/JfOr9p9zMwqpVQN4pvANyWdFhF31DCmuqjmRDlIV3ad5wlzZjZ2lLPUxj2S/pSku+lA11JE/HHVoqqDak6UK+jp7uBfvbKrmY0R5RSpvwwcCfw+8BNgHkk3U0Opxo5yA/XMP7iyq5nZaFdOgjgmIj4K7IqIL5FMmvsf1Q2r9qo5Ua6gZ15hRrW7mcxs9CsnQRT2fdgu6URgOnBE9UKqj2pOlCuYUVjZdf22qt7HzKwSyukIX5bu8vZR4CZgCvCxqkZVB0kLopx8OTI93R3c+fiWqt/HzGykhvyJGBH/HhHbIuInEXFURBwxxI5wY1JSg6j+fXq6O9j47D6e2rGn+jczMxuBUhPlPljqjRHxL5UPp35yUbsWBMCqdduZ/ZJJVb+fmdnhKvUTcWr61UuyJ/Xc9Ov9wCnVD622qj1RruD4OdMY39riQrWZjXqlJsp9HEDS7cApEbEzfX4p8J2aRFcjEUEuX92JcgUT2lo5bs40JwgzG/XK6VN5AbA/83x/+lrDyEfyvRYtCICTuzu474kd5Ao3NjMbhcpJENcAv5R0adp6+AWwvJpB1VpfPg9Qs2W4e7q9squZjX7ljGL6R+A9wLb06z0R8X+rHVgtpfmhpgkCPGHOzEa3UluOTku/zwTWkCy58WVgbfpaSZKulrRJ0v1DnLdEUp+kcwfeX9IGSVeU8TlG5EALosoT5QoWdLYzo32cd5gzs1Gt1ES5r5Is930XyRajBUqfHzXEtZcDV5B0URUlqRW4DLi5yOF/AG4f4h4VUesWhCQWd3tlVzMb3QZtQUTE69Lvi9IJcoWvRRExVHIgIm4Htg5x2kUkO9Ztyr4o6VSSQnixxFFxta5BACye18Ejm3by3L6+mt3TzGw4Sk2UKznXISLuHsmNJc0F3gycCSzJvN4CfAZ4J/DqIa5xAXABwPz5h78JTy6SBlItE0TP/A4i4N4N23n50V01u6+ZWblKdTF9psSxAM4a4b0vBz4cEXn17/u/EPhuRGzQEDWBiFgGLAPo7e097DGjheGmtRrmCgdXdr3ytsd45OmdLOiczILOdubNaGd8Ww3W/DAzG0KpiXJnVvnevcB1aRLoAs6R1AecBrxC0oUkCwOOl/RcRPx1tQIpJIhaTJQrmDF5PK9fPIdbHtzIfz36zIHXWwSzp09iYVc782cmSWNh58HH3mjIzGqlrJ826TLfx9N/R7lBi8/liIhFmesvB74dESuAFZnXlwK91UwOUJ8WBMC/nn8yEcHm5/axbstu1m7Zzdqtu1m7ZRdrt+zmBw88zdZd+/u9p2vK+KS1MbOd+Z3tLOyczPzOdhbMbGfm5PEM1eoyMyvXkAlC0iXAGSQJ4rvAa4CfUmJ0Uvq+a9P3dUnaAFwCjAMYbavB9uVrX4MokMQRUydyxNSJ9C48dPTws3ufzySPXax9Jvl+5+Nb+MaqJ4hMx9qUCW0s6GxnQdriWNiZJJEFnZOZPW1iTVtIZjb2ldOCOBdYDNwTEe+R9ALgK0O9KSLOLzeIiFg6yOvLqcGs7XwdE8RQpk0cx4lzp3Pi3OmHHNv7fI4N25LksWbLbtZt2cXarbt56Kmd/PDXG3k+dzB7jG9roXvGJBZ0Tmb+zKTbakHa+uh23cPMiignQexJC8l96eS5TUB3leOqqQMtiDHWPTNxXCvHHDGVY46YesixXD54cvse1m3dzZotu/p1Yd35+BZ2788dOLdQ91iQJo0FaZdVofUxxXUPs6ZUzv/8lZI6gC+STJp7DrijqlHVWG4UtyAOV2uL6J7ZTvfMdn7nmP7DaCOCZ57bz7qtu1jzTJI0Cq2PweoeSasjrXdkurBc9zBrXKXmQXwe+GpEXJi+dJWk7wPTIuLemkRXI42YIEqRxKypE5g1dQKnLji07rFz7/NJayOte6zbkrRCBqt7zJ/Z3m/U1YKZ7Szoct3DbKwr1YJ4BPi0pNnAfwLXRsQ9tQmrtuoxUW40m1pm3WPtlt0HurCK1j1aW5g3c1LS8pjZng7ZTVoh82ZMYkJbay0/lpkNU6l5EJ8FPitpAXAecLWkScC1JMnikRrFWHUHh7m6UDuUcuse/Udd7eYXj29hV6buIcGcA3WPQ0ddue5hVn9D/i+MiLUkC+pdJulk4GrgY0DD/Pp3cKJcnQMZ4/rXPfofy9Y9DnRfpXWPmx/YyJZB6h4HRl1lurA6Xfcwq4ly5kG0kcx9OA94FXAbcGlVo6oxtyCqr9y6x8BRV7/87VZWDFL3WNB5cLJgYdTV7OmT3FVoViGlitS/B5wPnAP8ErgOuCAidtUotpo5OFGuzoE0saHrHnsOjLpal842f3jjTn70YPG6x4KZmSG7aRdW90zXPcyGo1QL4m9I9oT4q4jYVqN46uLgRDlniNEoqXtM4ZgjphxyLJcPntqxJx1pdXDUVaH1UazuccioK9c9zIoqVaQe6WqtY8ZYnShnSd1j3oxkFdyXF6l7bNm1/2C9I9OFVazu0Tl5/MH1rWa295s46LqHNSP/ykTzzYNoFpLomjKBrikTOHXBjEOOZ+seyfekC6tY3WPy+Fbmd2ZGWmVGXbnuYY3KCQIniGZVqu6xry/H+q17Dhl19fDGndzy4Cb25/IHzh1Y98h2YbnuYWOZEwSeKGeHmtBWXt1j7dbd/bqwfrVmW79tZLN1j2yXVeH51InjavmxzIbFCQLI1WFPahu7+tU9BhzL1j0Gjrr60YMbeea54nWPgaOuFnROdt3D6s4JAij0FtR6wyBrPEPVPZ7b18faLbsOjLoqdGH9as02vrn6yaJ1j2Rtq6TuUUggrntYLThB4BaE1c6UCW2cMGc6J8wpXvfYsG3PgcURCwX0Rzbt5McP9a97jGsV3TPai466ct3DKsUJgvruKGdWMKGtlaNnTeHoWcXrHk8/u/dArSPbhbWySN1j9rSJA7akPdj6cN3DyuUEwejeUc4Mkn+bczsmMbdjEi8/uv+xiGDrrv39uqwKrZBidY+Zk8dnNoVKurAKo666prjuYQc5QeCJcja2SaJzygQ6y6h7ZEdd/WrNNm5a/ST5weoeA0Zdzelw3aPZOEGQmQfR6n/81njKrXsUVtddu2U3jw5R9xg46mrejHYmjnPdo9E4QZBJEG5BWJMpt+4xcNTVXWu2sXOQuseCmZP7jbqa39nONNc9xiQnCDxRzqyYcuoeyX7mmSXat+7mloeK1z36TRbMPHbdY/RyggByOScIs+HI1j1OmV+87rGuMNIqM+pq5ZptfGtA3aN9fGuyPEnnwRZHofXhukd9VS1BSLoaeB2wKSJOLHHeEuAO4LyIuCHd4vQbQAswDvjXiLiqWnFCpgXh32LMKmLKhDaOnzON4+dMO+TY/r58sq/51t2sfWbXgVbIo5t28uOHN7G/r3/dY96M9qKjrlz3qL5qtiCWA1cA1wx2gqRWku1Mb868/BRwWkTskzQFuF/STRHxZLUCzeWDFkGLf1Mxq7rxbS0cNWsKR82aAi/qfyyf1j2yXVaFLqxidY8jp01Mk8fkg7sLuu5RMVVLEBFxu6SFQ5x2EXAjsCTzvmzn5QSSlkRV5fLhZqzZKNDSIuZ0TGLOIHWPbbuf77cl7dq0aH7LQ5t45rl9/c6f0T7u4EirzKir+Z3tzJoywXWPMtStBiFpLvBm4EwyCSI91g18BzgGuHiw1oOkC4ALAObPn3/YsThBmI1+kpg5eTwzJ48vWvfYta/vQK1j7YE5H7u4a+3gdY/sXI9C3WP29Im0ef9hoL5F6suBD0dEfmAmj4j1wEmS5gArJN0QERsHXiAilgHLAHp7e2Pg8XL15cP1B7MxbnKZdY/sqKvHNu/i1oc3F617FBt11T2zueoe9UwQvcB1aXLoAs6R1BcRKwonRMSTku4HXgHcUK1A3IIwa2z96h4D5A/M9zg46mpd2n1199ridY/CqKv5heXZ0xrI9EmNVfeoW4KIiEWFx5KWA9+OiBWS5gFbImKPpBnA7wL/r5qxOEGYNa9s3eO0ozv7HSvUPdZu2ZXsZ/5MkjjWlah7FLamPTDqKk0iY7HuUc1hrtcCZwBdkjYAl5AMW2WIYavHAZ+RFICAT0fEfRIvo+IAAApkSURBVNWKE5Jhrq0t7nM0s/6ydY+TB6l7rMvuKph2YZVT98jO/RitdY9qjmI6fxjnLs08/iFwUjViGkwuF4zCvxszG+UmT2jjuNnTOG528brHE9v39Bt1tW7rrqJ1j7YWMW/GpH6LIxaSRz3rHp5JTdKCaHMLwswqaHxbC4u6JrOoa/Ihx/L5YOPOvemWtP1HXd29bhs79/b1O3/29IlFR11Vu+7hBEE6Uc75wcxqpKVFzJ4+idnTi9c9thfmexzovkqSx60Pb2bzzg39zp/RPo6XH9PF599+SsXjdIIgSRBuQZjZaCCJGZPHM6OMukeh9TGjfXxVYnGCwKOYzGzsKFX3qDT/2gz05fOeKGdmNoATBJDLe6lvM7OBnCCAXD7vBGFmNoATBJALtyDMzAZygsAtCDOzYpwg8CgmM7NinCBIE4RHMZmZ9eMEQTpRrtUJwswsywkCdzGZmRXjBIF3lDMzK8YJArcgzMyKcYLACcLMrBgnCAo7yjlBmJllOUHgFoSZWTFOEDhBmJkV4wSBJ8qZmRXjBIEnypmZFeMEQbontVsQZmb9OEGQTJRrcw3CzKyfqiUISVdL2iTp/iHOWyKpT9K56fMeSXdIekDSvZLeVq0YC/L5oLXFudLMLKuaPxWXA2eXOkFSK3AZcHPm5d3AuyLihPT9l0vqqFaQkC614fxgZtZP1X4sRsTtwNYhTrsIuBHYlHnfIxHxaPr4yfTYrGrFCYWJcs4QZmZZdfupKGku8GbgyhLnvBQYDzw2yPELJK2UtHLz5s2HHUvOLQgzs0PU88fi5cCHIyJf7KCk2cCXgfcMdk5ELIuI3ojonTXr8BoZEZEmCGcIM7Ostjreuxe4Tsnw0i7gHEl9EbFC0jTgO8BHIuLOagaRj+S7J8qZmfVXtwQREYsKjyUtB76dJofxwDeAayLihmrHkUszhCfKmZn1V7UEIela4AygS9IG4BJgHEBEXFXirW8FXgl0SlqavrY0IlZVI85CgvBEOTOz/qqWICLi/GGcuzTz+CvAV6oRUzF9+aS84YlyZmb9NX1lNs0PXs3VzGyApk8QhRaEE4SZWX9NnyDaWlt47Utms7Brcr1DMTMbVeo5zHVUmD5pHJ9/xyn1DsPMbNRp+haEmZkV5wRhZmZFOUGYmVlRThBmZlaUE4SZmRXlBGFmZkU5QZiZWVFOEGZmVpQiot4xVISkzcDaw3x7F/BMBcMZC/yZm4M/c3MYyWdeEBFFd1xrmAQxEpJWRkRvveOoJX/m5uDP3Byq9ZndxWRmZkU5QZiZWVFOEIll9Q6gDvyZm4M/c3Ooymd2DcLMzIpyC8LMzIpygjAzs6KaKkFIOlvSw5J+I+mvixyfIOlr6fFfSFpY+ygrq4zP/EFJv5Z0r6RbJC2oR5yVNNRnzpz3h5JC0pgfElnOZ5b01vTv+gFJX611jJVWxr/t+ZJulXRP+u/7nHrEWSmSrpa0SdL9gxyXpM+lfx73Shr5TmgR0RRfQCvwGHAUMB5YDRw/4JwLgavSx+cBX6t33DX4zGcC7enjDzTDZ07PmwrcDtwJ9NY77hr8PR8L3APMSJ8fUe+4a/CZlwEfSB8fD6ypd9wj/MyvBE4B7h/k+DnA9wABLwN+MdJ7NlML4qXAbyLi8YjYD1wHvHHAOW8EvpQ+vgF4lSTVMMZKG/IzR8StEbE7fXonMK/GMVZaOX/PAP8AXAbsrWVwVVLOZ34f8PmI2AYQEZtqHGOllfOZA5iWPp4OPFnD+CouIm4HtpY45Y3ANZG4E+iQNHsk92ymBDEXWJ95viF9reg5EdEH7AA6axJddZTzmbPeS/IbyFg25GdOm97dEfGdWgZWReX8Pb8QeKGkn0m6U9LZNYuuOsr5zJcC75S0AfgucFFtQqub4f5/H1LbiMKxhiHpnUAvcHq9Y6kmSS3AvwBL6xxKrbWRdDOdQdJKvF3SSyJie12jqq7zgeUR8RlJpwFflnRiROTrHdhY0UwtiCeA7szzeelrRc+R1EbSLN1Sk+iqo5zPjKRXAx8B3hAR+2oUW7UM9ZmnAicCt0laQ9JXe9MYL1SX8/e8AbgpIp6PiN8Cj5AkjLGqnM/8XuA/ASLiDmAiyaJ2jaqs/+/D0UwJ4lfAsZIWSRpPUoS+acA5NwHvTh+fC/w40urPGDXkZ5Z0MvBvJMlhrPdLwxCfOSJ2RERXRCyMiIUkdZc3RMTK+oRbEeX8215B0npAUhdJl9PjtQyywsr5zOuAVwFIOo4kQWyuaZS1dRPwrnQ008uAHRHx1Egu2DRdTBHRJ+nPgB+QjIC4OiIekPT3wMqIuAn4D5Jm6G9IikHn1S/ikSvzM38KmAJcn9bj10XEG+oW9AiV+ZkbSpmf+QfA/5T0ayAHXBwRY7Z1XOZn/ivgi5L+kqRgvXQs/8In6VqSJN+V1lUuAcYBRMRVJHWWc4DfALuB94z4nmP4z8vMzKqombqYzMxsGJwgzMysKCcIMzMrygnCzMyKcoIwM7OinCCsYUnKSVol6X5J35LUUYV73DbcSXaS/j6dnDjce71J0vEjvY5ZuZwgrJHtiYieiDiRZF7Ln9Y7IEmtEfGxiPjRYbz9TSSrkgIwguuYlcUJwprFHaQLl0k6WtL3Jd0l6b8kvTjz+p2S7pP0CUnPpa+fIenbhQtJukLS0oE3kHSlpJXpfgsfz7y+RtJlku4G3iJpuaRzJfWmLZxV6T0jPf99kn4labWkGyW1S3o58AbgU+n5Rxeuk77nVem+B/el+wZMyNz745LuTo+9uEp/vtaAnCCs4UlqJVlyoTCLehlwUUScCnwI+EL6+meBz0bES0jWLhquj0REL3AScLqkkzLHtkTEKRFxXeGFiFiZtnB6gO8Dn04PfT0ilkTEYuBB4L0R8fM0/ovT9zyW+XwTgeXA29LY20j29ih4JiJOAa5MP69ZWZwgrJFNkrQKeBp4AfBDSVOAl5MsLbKKZB2qwpr5pwHXp48PZ8e1t6athHuAE8h0BwFfG+xNkt5GshFMYVe0E9OWzX3AO9JrlfIi4LcR8Uj6/Eskm8sUfD39fhewsIzPYQY00VpM1pT2RESPpHaSNXv+lOQ37e3pb+3l6qP/L1MTB54gaRHJb+dLImKbpOUDzttV7MKSTiTZt+CVEZFLX14OvCkiVqddWWcMI9ZiCiv05vD/eRsGtyCs4aU75v05yeJtu4HfSnoLHNjHd3F66p3AH6aPsws1rgWOV7JneQfpCqEDTCNJAjskvQB4zVBxpde6FnhXRGRXGZ0KPCVpHEkLomBnemygh4GFko5Jn/8R8JOh7m82FCcIawoRcQ9wL8kmMu8A3itpNfAAB7eq/N/AByXdCxxDsqMgEbGeZF+B+9Pv9xS5/ur09YdIuqd+VkZYbwQWkKw4uirt8gL4KPCL9BoPZc6/Drg4LUYfnbn3XpKVO69Pu6XywFVl3N+sJK/mapZKu6L2RERIOg84PyKK7Wdt1hTcH2l20KnAFUo2xtgO/HGd4zGrK7cgzMysKNcgzMysKCcIMzMrygnCzMyKcoIwM7OinCDMzKyo/wb4Q5V6EJzbgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "understanding_the_effect(\"Regularization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "understanding_the_effect(\"Batch size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 - 1s - loss: 3.0226 - masked_rmse_loss: 1.6020 - val_loss: 1.3706 - val_masked_rmse_loss: 1.1717\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.37057, saving model to weights-best-model.hdf5\n",
      "Epoch 2/10\n",
      "26/26 - 0s - loss: 1.1600 - masked_rmse_loss: 1.0766 - val_loss: 1.2507 - val_masked_rmse_loss: 1.1192\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.37057 to 1.25071, saving model to weights-best-model.hdf5\n",
      "Epoch 3/10\n",
      "26/26 - 0s - loss: 1.0824 - masked_rmse_loss: 1.0401 - val_loss: 1.1648 - val_masked_rmse_loss: 1.0806\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25071 to 1.16479, saving model to weights-best-model.hdf5\n",
      "Epoch 4/10\n",
      "26/26 - 0s - loss: 1.0061 - masked_rmse_loss: 1.0026 - val_loss: 1.0844 - val_masked_rmse_loss: 1.0427\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.16479 to 1.08438, saving model to weights-best-model.hdf5\n",
      "Epoch 5/10\n",
      "26/26 - 0s - loss: 0.9174 - masked_rmse_loss: 0.9574 - val_loss: 0.9948 - val_masked_rmse_loss: 0.9987\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.08438 to 0.99480, saving model to weights-best-model.hdf5\n",
      "Epoch 6/10\n",
      "26/26 - 0s - loss: 0.8831 - masked_rmse_loss: 0.9394 - val_loss: 0.9805 - val_masked_rmse_loss: 0.9915\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.99480 to 0.98047, saving model to weights-best-model.hdf5\n",
      "Epoch 7/10\n",
      "26/26 - 0s - loss: 0.8602 - masked_rmse_loss: 0.9274 - val_loss: 0.9614 - val_masked_rmse_loss: 0.9816\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.98047 to 0.96137, saving model to weights-best-model.hdf5\n",
      "Epoch 8/10\n",
      "26/26 - 0s - loss: 0.8451 - masked_rmse_loss: 0.9193 - val_loss: 0.9509 - val_masked_rmse_loss: 0.9763\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.96137 to 0.95086, saving model to weights-best-model.hdf5\n",
      "Epoch 9/10\n",
      "26/26 - 0s - loss: 0.8375 - masked_rmse_loss: 0.9152 - val_loss: 0.9512 - val_masked_rmse_loss: 0.9764\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.95086\n",
      "Epoch 10/10\n",
      "26/26 - 0s - loss: 0.8313 - masked_rmse_loss: 0.9116 - val_loss: 0.9423 - val_masked_rmse_loss: 0.9718\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.95086 to 0.94226, saving model to weights-best-model.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Lets fit the best model\n",
    "\n",
    "best_ae_model = AutoEncContentModel(best_params[\"Layers\"],\n",
    "                                    epochs,\n",
    "                                    int(best_params[\"Batch size\"]),\n",
    "                                    activation, dropout,\n",
    "                                    float(best_params[\"Learning Rate\"]),\n",
    "                                    float(best_params[\"Regularization\"]))\n",
    "\n",
    "X = [ratings_train, df_users[['occupation', 'age']].values]\n",
    "y = ratings_train\n",
    "\n",
    "best_model, hist = best_ae_model.fit(X, y, verbose=2)\n",
    "\n",
    "\n",
    "# # Input - We add content information for users\n",
    "# X = [ratings_train, df_users[['occupation', 'age']].values]\n",
    "# y = ratings_train\n",
    "\n",
    "# # Train\n",
    "# model, hist = autoenc_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_ae_model.plot_loss_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 0s 1ms/step - loss: 0.8970 - masked_rmse_loss: 0.9470\n",
      "Model RMSE on test set: 0.9469799995422363\n"
     ]
    }
   ],
   "source": [
    "test_rmse = best_ae_model.model.evaluate(X_test, y_test)[1]\n",
    "print(\"Model RMSE on test set:\", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3459, 6040)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test = best_ae_model.model.predict(X_test) * (X_test == 0)\n",
    "predicted_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG score: 0.2794667005511281\n"
     ]
    }
   ],
   "source": [
    "print(\"NDCG score:\", ndcg_score(ratings_test, predicted_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "meUMpBfj2mop",
    "TJhKSA0SESJ4",
    "zdNTZ4YxESJ6",
    "8oLE3tfwESJ8",
    "Orsa05gb82jQ"
   ],
   "name": "AutoRec-improved.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
